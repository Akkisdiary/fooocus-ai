{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2596b1a8-4c39-4a81-9a5a-c4565faad76f",
   "metadata": {},
   "source": [
    "## Python 3.10\n",
    "Python 3.10 is the recommended Python version for running the WebUI. Paperspace uses Python 3.9 for their containers so you must use a custom container. Luckily, I've created a container for you to use.\n",
    "First, delete your current notebook and create a new one following these instructions: https://docs.paperspace.com/gradient/notebooks/runtimes/#how-to-specify-a-custom-container\n",
    "Make sure to use this container image: `cyberes/gradient-base-py3.10`\n",
    "You can use the block below to test your Python version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a311c-b6b2-4fc2-8192-1facfe1402cf",
   "metadata": {},
   "source": [
    "#### Base Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7ffc35-64a7-4de6-95f3-d3aeabc8cd9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T13:46:27.328321Z",
     "iopub.status.busy": "2024-12-22T13:46:27.327050Z",
     "iopub.status.idle": "2024-12-22T13:46:59.483747Z",
     "shell.execute_reply": "2024-12-22T13:46:59.482697Z",
     "shell.execute_reply.started": "2024-12-22T13:46:27.328257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n",
      "2024-12-22 13:46:28,353 | INFO : Your Python version is good: 3.10.10\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your CivitAI Token?  ce7f051c7d8a244671e1737f840dfb6f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-22 13:46:57,753 | INFO : Creating Symlinks...\n",
      "2024-12-22 13:46:57,755 | INFO : /storage/stable-diffusion/stable-diffusion-webui -> /notebooks/stable-diffusion-webui\n",
      "2024-12-22 13:46:57,759 | INFO : /storage/stable-diffusion/stable-diffusion-webui/outputs -> /notebooks/outputs\n",
      "2024-12-22 13:46:57,762 | INFO : /storage -> /notebooks/storage\n",
      "2024-12-22 13:46:57,767 | DEBUG : Symlink broken, removing: /notebooks/models\n",
      "2024-12-22 13:46:57,772 | INFO : /tmp/stable-diffusion-models -> /notebooks/models\n",
      "2024-12-22 13:46:57,774 | DEBUG : /storage/stable-diffusion/stable-diffusion-webui already downloaded, updating...\n",
      "From https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
      " * branch              master     -> FETCH_HEAD\n",
      "Already up to date.\n",
      "Stored 'symlink_to_notebooks' (bool)\n",
      "Stored 'model_storage_dir' (PosixPath)\n",
      "Stored 'repo_storage_dir' (PosixPath)\n",
      "Stored 'export_storage_dir' (str)\n",
      "Stored 'activate_xformers' (bool)\n",
      "Stored 'link_novelai_anime_vae' (bool)\n",
      "Stored 'activate_deepdanbooru' (bool)\n",
      "Stored 'activate_medvram' (bool)\n",
      "Stored 'disable_pickle_check' (bool)\n",
      "Stored 'gradio_port' (bool)\n",
      "Stored 'gradio_auth' (bool)\n",
      "Stored 'search_paperspace_datasets' (bool)\n",
      "Stored 'ui_theme' (NoneType)\n",
      "Stored 'insecure_extension_access' (bool)\n",
      "Stored 'pip_cache_dir' (NoneType)\n",
      "Stored 'gradio_queue' (bool)\n",
      "Stored 'install_pip_xformers' (bool)\n"
     ]
    }
   ],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd /notebooks\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def download_civit_model(url: str, output_path: str, token: str):\n",
    "\n",
    "    CHUNK_SIZE = 1638400\n",
    "    USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}',\n",
    "        'User-Agent': USER_AGENT,\n",
    "    }\n",
    "\n",
    "    # Disable automatic redirect handling\n",
    "    class NoRedirection(urllib.request.HTTPErrorProcessor):\n",
    "        def http_response(self, request, response):\n",
    "            return response\n",
    "        https_response = http_response\n",
    "\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener(NoRedirection)\n",
    "    response = opener.open(request)\n",
    "\n",
    "    if response.status in [301, 302, 303, 307, 308]:\n",
    "        redirect_url = response.getheader('Location')\n",
    "\n",
    "        # Extract filename from the redirect URL\n",
    "        parsed_url = urlparse(redirect_url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        content_disposition = query_params.get('response-content-disposition', [None])[0]\n",
    "\n",
    "        if content_disposition:\n",
    "            filename = unquote(content_disposition.split('filename=')[1].strip('\"'))\n",
    "        else:\n",
    "            raise Exception('Unable to determine filename')\n",
    "\n",
    "        response = urllib.request.urlopen(redirect_url)\n",
    "    elif response.status == 404:\n",
    "        raise Exception('File not found')\n",
    "    else:\n",
    "        raise Exception('No redirect found, something went wrong')\n",
    "\n",
    "    total_size = response.getheader('Content-Length')\n",
    "\n",
    "    if total_size is not None:\n",
    "        total_size = int(total_size)\n",
    "\n",
    "    if (Path(output_path)/filename).is_file():\n",
    "        logger.warn(f'{Path(output_path)/filename} already exists, skipping download')\n",
    "        return\n",
    "\n",
    "    output = Path(output_path)\n",
    "    output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(Path(output_path)/filename, 'wb') as f:\n",
    "        downloaded = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            chunk_start_time = time.time()\n",
    "            buffer = response.read(CHUNK_SIZE)\n",
    "            chunk_end_time = time.time()\n",
    "\n",
    "            if not buffer:\n",
    "                break\n",
    "\n",
    "            downloaded += len(buffer)\n",
    "            f.write(buffer)\n",
    "            chunk_time = chunk_end_time - chunk_start_time\n",
    "\n",
    "            if chunk_time > 0:\n",
    "                speed = len(buffer) / chunk_time / (1024 ** 2)  # Speed in MB/s\n",
    "\n",
    "            if total_size is not None:\n",
    "                progress = downloaded / total_size\n",
    "                sys.stdout.write(f'\\rDownloading: {filename} [{progress*100:.2f}%] - {speed:.2f} MB/s')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    hours, remainder = divmod(time_taken, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        time_str = f'{int(hours)}h {int(minutes)}m {int(seconds)}s'\n",
    "    elif minutes > 0:\n",
    "        time_str = f'{int(minutes)}m {int(seconds)}s'\n",
    "    else:\n",
    "        time_str = f'{int(seconds)}s'\n",
    "\n",
    "    sys.stdout.write('\\n')\n",
    "    logger.info(f'Download completed. File saved as: {Path(output_path)/filename}')\n",
    "    logger.info(f'Downloaded in {time_str}')\n",
    "\n",
    "\n",
    "def create_symlink(source, dest):\n",
    "    if dest.is_symlink() and not dest.exists():\n",
    "        logger.debug(f'Symlink broken, removing: {dest}')\n",
    "        dest.unlink()\n",
    "    if not dest.exists():\n",
    "        os.symlink(src, dest)\n",
    "    logger.info(f'{os.path.realpath(dest)} -> {dest}')\n",
    "\n",
    "def create_symlink_2(source, dest):\n",
    "    if os.path.isdir(dest):\n",
    "        dest = Path(dest, os.path.basename(source))\n",
    "    if not dest.exists():\n",
    "        os.symlink(source, dest)\n",
    "    logger.info(f'{source} -> {Path(dest).absolute()}')\n",
    "\n",
    "\n",
    "def clone_repo(dest, remote, branch):\n",
    "    if not (dest / '.git').exists():\n",
    "        # It's possible that the repo already exists but the repo has not been downloaded.\n",
    "        # We will init the repo manually.\n",
    "        !mkdir -p \"{dest}\"\n",
    "        %cd \"{dest}\"\n",
    "        !git init\n",
    "        !git remote add origin \"{remote}\"\n",
    "        !git fetch origin \"{branch}\"\n",
    "        !git checkout -t \"origin/{branch}\" -f\n",
    "    else:\n",
    "        logger.debug(f'{dest} already downloaded, updating...')\n",
    "        !cd \"{dest}\" && git pull origin \"{branch}\" # no % so we don't interfere with the main process\n",
    "\n",
    "\n",
    "def download_whl(url, binary_name='xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl'):\n",
    "    tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "    !wget \"{url}\" -O \"{tmp_dir}/{binary_name}\"\n",
    "    return os.path.join(tmp_dir, binary_name)\n",
    "\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    for file in Path(dir).iterdir():\n",
    "        if file.is_symlink() and not file.exists():\n",
    "            logger.debug(f'Symlink broken, removing: {file}')\n",
    "            file.unlink()\n",
    "\n",
    "\n",
    "def link_ckpts(source_path, webui_sd_model_path):\n",
    "    # Link .ckpt and .safetensor/.st files (recursive)\n",
    "    logger.info(f'Linking .ckpt and .safetensor/.safetensors/.st files in {source_path}')\n",
    "    source_path = Path(source_path)\n",
    "    for file in [\n",
    "        p for p in source_path.rglob('*')\n",
    "        if p.suffix in ['.ckpt', '.safetensor', '.safetensors', '.st']\n",
    "    ]:\n",
    "        if Path(file).parent.parts[-1] not in ['hypernetworks', 'vae', 'embeddings'] :\n",
    "            if not (webui_sd_model_path / file.name):\n",
    "                logger.debug(f'New model: {file.name}')\n",
    "            create_symlink_2(file, webui_sd_model_path)\n",
    "    # Link config yaml files\n",
    "    logger.info(f'Linking config .yaml files in {source_path}')\n",
    "    for file in source_path.glob('*.yaml'):\n",
    "        create_symlink_2(file, webui_sd_model_path)\n",
    "\n",
    "\n",
    "def install_xformers(install_pip_xformers):\n",
    "    if install_pip_xformers:\n",
    "        logger.info('Installing xformers through pip...')\n",
    "        !pip install --no-dependencies xformers\n",
    "    else:\n",
    "        xformers_whl = None\n",
    "        found_xformers_whls = glob('/notebooks/xformers-*')\n",
    "        if len(found_xformers_whls) == 1:\n",
    "            logger.info('Installing xformers using your pre-built wheel...')\n",
    "            xformers_whl = found_xformers_whls[0]\n",
    "            delete_whl = False\n",
    "        elif len(found_xformers_whls) > 1:\n",
    "            logger.info('Found more than one Xformers wheel in /notebooks so not doing anything!')\n",
    "        else:\n",
    "            logger.info('Installing xformers from wheels on Github...')\n",
    "            delete_whl = True\n",
    "\n",
    "            # Set up pip packages\n",
    "            !pip uninstall -y torch torchvision torchaudio protobuf # Remove existing pytorch install.\n",
    "            # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # Install pytorch for cuda 11.3\n",
    "            s = subprocess.getoutput('nvidia-smi -L')\n",
    "            logger.info(f'Your SMI: {s}')\n",
    "            if 'A4000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/raw/main/a4000/xformers-0.0.18%2Bda27862.d20230413-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A5000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A6000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'P5000' in s:\n",
    "                xformers_whl = download_whl('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/p5000/xformers-0.0.16%2B6f3c20f.d20230127-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 4000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 5000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A100' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'M4000' in s:\n",
    "                logger.warning('xformers for M4000 hasn\\'t been built yet.')\n",
    "                # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            else:\n",
    "                logger.warning('GPU not matched to xformers binary so a one-size-fits-all binary was installed. If you have any issues, please build xformers using the Tools block below.')\n",
    "                xformers_whl = download_whl('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "        if xformers_whl:\n",
    "            !pip uninstall -y xformers\n",
    "            # We're going to install xformers without installing any of its dependencies since they should already be installed.\n",
    "            # If you have any issues then replacing --no-dependencies with --force-reinstall\n",
    "            !pip install --no-dependencies \"{xformers_whl}\"\n",
    "            if delete_whl:\n",
    "                !rm -rf \"{xformers_whl}\"\n",
    "\n",
    "\n",
    "py_version = sys.version.split(' ')[0]\n",
    "if int(py_version.split('.')[1]) < 10:\n",
    "    logger.info(f'Your Python version is less than 3.10 -> {py_version}')\n",
    "else:\n",
    "    logger.info(f'Your Python version is good: {py_version}')\n",
    "\n",
    "# Other optional settings\n",
    "# You don't have to change these if you don't want to.\n",
    "symlink_to_notebooks = True                            # Enables the creation of symlinks back to /notebooks/\n",
    "activate_xformers = True                               # Enables the xformers optimizations using pre-built wheels.\n",
    "                                                       # Setting to True will automatically set up your environment/machine for xformers. \n",
    "install_pip_xformers = False                           # Install xformers through pip. Probably won't work because it needs Torch 2.0\n",
    "link_novelai_anime_vae = True                          # Enables the linking of animevae.pt to each of the NovelAI models.\n",
    "                                                       # Set to True if you've downloaded both the NovelAI models and hypernetworks.\n",
    "activate_deepdanbooru = False                          # Enable and install DeepDanbooru -> https://github.com/KichangKim/DeepDanbooru\n",
    "activate_medvram = True                                # Enable medvram option.\n",
    "                                                       # These are model optimizations which will reduce VRAM usage at the expense of some speed.\n",
    "                                                       # Set to False if you have a lot of VRAM.\n",
    "disable_pickle_check = False                           # Disable the automatic check for unexpected data in model files.\n",
    "                                                       # Leave this set to False unless you have a reason to disable the check.\n",
    "gradio_port = False                                    # Launch Gradio on a specific port. Set to False to let Gradio choose a port.\n",
    "                                                       # This disables online Gradio app mode and you will only be able to access it on your local network.\n",
    "gradio_auth = False                                    # Enable gradio_auth and insecure-extension-access option.\n",
    "                                                       # Set to a username:password (for example: \"me:password\") to enable.\n",
    "search_paperspace_datasets = True                      # Enable searching for checkpoints in /datasets to link to the webui\n",
    "ui_theme = None                                        # Set the WEB UI theme. Values can be None (default) or 'dark'.\n",
    "insecure_extension_access = False                      # Force enable extensions without a password.\n",
    "                                                       # If you don't set a password anyone can install and run arbitrary code on your machine!\n",
    "                                                       # Instead, use gradio_auth which will automatically enable extensions when set.\n",
    "gradio_queue = False                                   # Uses gradio queue; experimental option; breaks restart UI button.\n",
    "civitai_token = input('Your CivitAI Token? ')\n",
    "\n",
    "# Choose where to store your model checkpoints.\n",
    "model_storage_dir = '/tmp/stable-diffusion-models' # Free Tier\n",
    "# model_storage_dir = '/storage/models' # Paid Tier\n",
    "\n",
    "# Optional path settings\n",
    "repo_storage_dir = '/storage/stable-diffusion'         # Where to store your Stable Diffusion-related files.\n",
    "export_storage_dir = '/notebooks/exports'              # Where the generated images will be exported to.\n",
    "pip_cache_dir = None                                   # The installer can cache pip wheels so you don't have to re-download them\n",
    "                                                       # every time you start the machine. I recommed setting it to '/storage/pip/cache'\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "model_storage_dir = Path(model_storage_dir)\n",
    "stable_diffusion_webui_path = repo_storage_dir / 'stable-diffusion-webui'\n",
    "\n",
    "!mkdir -p \"{stable_diffusion_webui_path / 'outputs'}\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path / 'log'}\"\n",
    "\n",
    "symlinks = [\n",
    "    (stable_diffusion_webui_path, Path('/notebooks/stable-diffusion-webui')),\n",
    "    (stable_diffusion_webui_path / 'outputs', Path('/notebooks/outputs')),\n",
    "    # (stable_diffusion_webui_path / 'log', repo_storage_dir / 'stable-diffusion-webui' / 'outputs' / 'log'),\n",
    "    (Path('/storage'), Path('/notebooks/storage')),\n",
    "    (model_storage_dir, Path('/notebooks/models')),\n",
    "]\n",
    "if symlink_to_notebooks and repo_storage_dir != '/notebooks':\n",
    "    logger.info('Creating Symlinks...')\n",
    "    for src, dest in symlinks:\n",
    "        create_symlink(src, dest)\n",
    "\n",
    "clone_repo(\n",
    "    stable_diffusion_webui_path,\n",
    "    \"https://github.com/AUTOMATIC1111/stable-diffusion-webui\",\n",
    "    \"master\"\n",
    ")\n",
    "# ===================================================================================================\n",
    "# Save variables to Jupiter's temp storage so we can access it even if the kernel restarts.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir export_storage_dir activate_xformers link_novelai_anime_vae activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth search_paperspace_datasets ui_theme insecure_extension_access pip_cache_dir gradio_queue install_pip_xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eca8b-bb4e-479e-aa7a-379e53fa8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd \"{stable_diffusion_webui_path}\"\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade wheel setuptools\n",
    "\n",
    "if activate_xformers:\n",
    "    install_xformers(install_pip_xformers)\n",
    "\n",
    "import launch; launch.prepare_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9398faac-1687-46b0-bb8b-e33d2c9eef44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:28:17.045927Z",
     "iopub.status.busy": "2024-12-22T14:28:17.045367Z",
     "iopub.status.idle": "2024-12-22T14:28:43.712024Z",
     "shell.execute_reply": "2024-12-22T14:28:43.711045Z",
     "shell.execute_reply.started": "2024-12-22T14:28:17.045884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/stable-diffusion/stable-diffusion-webui\n",
      "2024-12-22 14:28:22,809 | DEBUG : Downloading Embedding https://civitai.com/api/download/models/253081 into /tmp/stable-diffusion-models/embeddings\n",
      "Downloading: InnaNobodySD15.pt [100.00%] - 45.05 MB/s\n",
      "2024-12-22 14:28:23,206 | INFO : Download completed. File saved as: /tmp/stable-diffusion-models/embeddings/InnaNobodySD15.pt\n",
      "2024-12-22 14:28:23,207 | INFO : Downloaded in 0s\n",
      "Downloading: analogMadness_v70.safetensors [100.00%] - 164.13 MB/s\n",
      "2024-12-22 14:28:43,647 | INFO : Download completed. File saved as: /tmp/stable-diffusion-models/analogMadness_v70.safetensors\n",
      "2024-12-22 14:28:43,648 | INFO : Downloaded in 20s\n",
      "2024-12-22 14:28:43,649 | INFO : Removing broken symlinks...\n",
      "2024-12-22 14:28:43,688 | INFO : Linking checkpoints...\n",
      "2024-12-22 14:28:43,689 | INFO : Linking .ckpt and .safetensor/.safetensors/.st files in /tmp/stable-diffusion-models\n",
      "2024-12-22 14:28:43,692 | INFO : /tmp/stable-diffusion-models/aZovyaPhotoreal_v3.safetensors -> /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/aZovyaPhotoreal_v3.safetensors\n",
      "2024-12-22 14:28:43,693 | INFO : /tmp/stable-diffusion-models/analogMadness_v70.safetensors -> /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/analogMadness_v70.safetensors\n",
      "2024-12-22 14:28:43,694 | INFO : Linking config .yaml files in /tmp/stable-diffusion-models\n",
      "2024-12-22 14:28:43,695 | INFO : Linking hypernetworks...\n",
      "2024-12-22 14:28:43,696 | INFO : Linking VAEs...\n",
      "2024-12-22 14:28:43,697 | INFO : Linking Loras...\n",
      "2024-12-22 14:28:43,698 | WARNING : Lora storage directory not found: /tmp/stable-diffusion-models/Lora\n",
      "2024-12-22 14:28:43,699 | INFO : Linking Embeddings...\n",
      "2024-12-22 14:28:43,700 | INFO : /tmp/stable-diffusion-models/embeddings/InnaNobodySD15.pt -> /storage/stable-diffusion/stable-diffusion-webui/embeddings/InnaNobodySD15.pt\n",
      "2024-12-22 14:28:43,701 | INFO : Linking .ckpt and .safetensor/.safetensors/.st files in /datasets\n",
      "2024-12-22 14:28:43,707 | INFO : /datasets/stable-diffusion-classic-v2/768-v-ema.ckpt -> /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/768-v-ema.ckpt\n",
      "2024-12-22 14:28:43,708 | INFO : Linking config .yaml files in /datasets\n"
     ]
    }
   ],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd \"{stable_diffusion_webui_path}\"\n",
    "\n",
    "# Make sure important directories exists\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{model_storage_dir}/vae\"\n",
    "!mkdir -p \"{model_storage_dir}/embeddings\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/models/hypernetworks\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/models/VAE\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/models/Lora\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/log/images\"\n",
    "\n",
    "if not model_storage_dir.exists():\n",
    "    logger.error(f'Your model storage directory does not exist: {model_storage_dir}')\n",
    "    sys.exit(1)\n",
    "\n",
    "embeddings_urls = [\n",
    "    \"https://civitai.com/api/download/models/253081\", # Inna Nobody\n",
    "]\n",
    "for url in embeddings_urls:\n",
    "    dest = model_storage_dir/'embeddings'\n",
    "    logger.debug(f'Downloading Embedding {url} into {dest}')\n",
    "    download_civit_model(url, dest, civitai_token)\n",
    "\n",
    "zovya_photoreal = \"https://civitai.com/api/download/models/474400\"\n",
    "download_civit_model(zovya_photoreal, model_storage_dir, civitai_token)\n",
    "\n",
    "analog_madness = \"https://civitai.com/api/download/models/261539?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n",
    "download_civit_model(analog_madness, model_storage_dir, civitai_token)\n",
    "\n",
    "webui_root_model_path = Path(stable_diffusion_webui_path, 'models')\n",
    "webui_sd_model_path = Path(webui_root_model_path, 'Stable-diffusion')\n",
    "webui_hypernetwork_path = Path(webui_root_model_path, 'hypernetworks')\n",
    "webui_vae_path = Path(webui_root_model_path, 'VAE')\n",
    "webui_lora_model_path = Path(webui_root_model_path, 'Lora')\n",
    "webui_embeddings_path = Path(stable_diffusion_webui_path, 'embeddings')\n",
    "\n",
    "# Check for broken symlinks and remove them\n",
    "logger.info('Removing broken symlinks...')\n",
    "delete_broken_symlinks(webui_sd_model_path)\n",
    "delete_broken_symlinks(webui_hypernetwork_path)\n",
    "delete_broken_symlinks(webui_vae_path)\n",
    "delete_broken_symlinks(webui_lora_model_path)\n",
    "delete_broken_symlinks(webui_embeddings_path)\n",
    "\n",
    "logger.info('Linking checkpoints...')\n",
    "link_ckpts(model_storage_dir, webui_sd_model_path)\n",
    "\n",
    "# Link hypernetworks\n",
    "logger.info('Linking hypernetworks...')\n",
    "hypernetwork_source_path = Path(model_storage_dir, 'hypernetworks')\n",
    "if hypernetwork_source_path.is_dir():\n",
    "    for file in hypernetwork_source_path.iterdir():\n",
    "        create_symlink_2(hypernetwork_source_path / file, webui_hypernetwork_path)\n",
    "else:\n",
    "    logger.warning(f'Hypernetwork storage directory not found: {hypernetwork_source_path}')\n",
    "\n",
    "# Link VAEs\n",
    "logger.info('Linking VAEs...')\n",
    "vae_source_path = Path(model_storage_dir, 'vae')\n",
    "if vae_source_path.is_dir():\n",
    "    for file in vae_source_path.iterdir():\n",
    "        create_symlink_2(vae_source_path / file, webui_vae_path)\n",
    "else:\n",
    "    logger.warning(f'VAE storage directory not found: {vae_source_path}')\n",
    "\n",
    "# Link Lora\n",
    "logger.info('Linking Loras...')\n",
    "lora_source_path = Path(model_storage_dir, 'Lora')\n",
    "if lora_source_path.is_dir():\n",
    "    for file in lora_source_path.iterdir():\n",
    "        create_symlink_2(lora_source_path / file, webui_lora_model_path)\n",
    "else:\n",
    "    logger.warning(f'Lora storage directory not found: {lora_source_path}')\n",
    "\n",
    "# Link Embeddings\n",
    "logger.info('Linking Embeddings...')\n",
    "embeddings_source_path = Path(model_storage_dir, 'embeddings')\n",
    "if embeddings_source_path.is_dir():\n",
    "    for file in embeddings_source_path.iterdir():\n",
    "        create_symlink_2(embeddings_source_path / file, webui_embeddings_path)\n",
    "else:\n",
    "    logger.warning(f'Embeddings storage directory not found: {embeddings_source_path}')\n",
    "\n",
    "\n",
    "if search_paperspace_datasets:\n",
    "    if Path('/datasets').is_dir():\n",
    "        link_ckpts('/datasets', webui_sd_model_path)\n",
    "    else:\n",
    "        logger.warning('No datasets mounted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb0d67b-887e-40fb-9ce0-2aa1d13efb9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:32:36.515999Z",
     "iopub.status.busy": "2024-12-22T14:32:36.515004Z",
     "iopub.status.idle": "2024-12-22T14:40:32.114095Z",
     "shell.execute_reply": "2024-12-22T14:40:32.112926Z",
     "shell.execute_reply.started": "2024-12-22T14:32:36.515938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/stable-diffusion/stable-diffusion-webui\n",
      "2024-12-22 14:32:36,527 | INFO : Launching A1111 WebUI\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "no module 'xformers'. Processing without...\n",
      "no module 'xformers'. Processing without...\n",
      "No module 'xformers'. Proceeding without it.\n",
      "*** Cannot import xformers\n",
      "    Traceback (most recent call last):\n",
      "      File \"/storage/stable-diffusion/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 160, in <module>\n",
      "        import xformers.ops\n",
      "    ModuleNotFoundError: No module named 'xformers'\n",
      "\n",
      "---\n",
      "Loading weights [9356775e08] from /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/aZovyaPhotoreal_v3.safetensors\n",
      "fatal: No names found, cannot describe anything.\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Creating model from config: /storage/stable-diffusion/stable-diffusion-webui/configs/v1-inference.yaml\n",
      "Running on public URL: https://97dea3762f5d042088.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Startup time: 15.1s (import torch: 5.4s, import gradio: 1.4s, setup paths: 3.0s, initialize shared: 0.6s, other imports: 0.5s, list SD models: 0.3s, load scripts: 1.5s, create ui: 1.1s, gradio launch: 1.3s).\n",
      "Applying attention optimization: Doggettx... done.\n",
      "Calculating sha256 for /storage/stable-diffusion/stable-diffusion-webui/embeddings/InnaNobodySD15.pt: d1ba65de60ae59500e6f2a304353e6971a30afc50aa0fae4c62ced4bdc0e2d17\n",
      "Model loaded in 7.8s (load weights from disk: 1.4s, create model: 0.8s, apply weights to model: 4.8s, apply half(): 0.1s, calculate empty prompt: 0.5s).\n",
      "Reusing loaded model aZovyaPhotoreal_v3.safetensors [9356775e08] to load analogMadness_v70.safetensors\n",
      "Calculating sha256 for /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/analogMadness_v70.safetensors: 3c5d7960a76dbc715ad1c4f2c4f948cd1f12ccd09d44cef243a7dd2cf82371bf\n",
      "Loading weights [3c5d7960a7] from /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/analogMadness_v70.safetensors\n",
      "Applying attention optimization: Doggettx... done.\n",
      "Weights loaded in 9.6s (send model to cpu: 0.3s, calculate hash: 7.1s, apply weights to model: 2.1s).\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\n",
      "  3%|█▍                                          | 1/30 [00:02<01:16,  2.62s/it]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:04<01:01,  2.18s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:40,  1.51s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:07<00:42,  1.65s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:08<00:43,  1.73s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:10<00:42,  1.78s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:12<00:41,  1.81s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:14<00:40,  1.83s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:16<00:38,  1.85s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:18<00:37,  1.86s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:20<00:35,  1.86s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:23<00:40,  2.22s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:23<00:29,  1.76s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:25<00:28,  1.80s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:27<00:27,  1.82s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:29<00:25,  1.84s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:31<00:24,  1.85s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:33<00:22,  1.86s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:35<00:20,  1.87s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:37<00:18,  1.87s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:39<00:16,  1.87s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:42<00:17,  2.23s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:42<00:12,  1.77s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:44<00:10,  1.81s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:46<00:09,  1.83s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:48<00:07,  1.85s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:50<00:05,  1.86s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:52<00:03,  1.87s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:54<00:01,  1.87s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:55<00:00,  1.87s/it]\u001b[A\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 30/30 [00:58<00:00,  1.96s/it]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                          | 1/30 [00:02<01:11,  2.47s/it]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:04<00:59,  2.13s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:05<00:40,  1.48s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:06<00:42,  1.64s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:08<00:43,  1.73s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:10<00:42,  1.78s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:12<00:41,  1.82s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:14<00:40,  1.84s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:16<00:38,  1.85s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:18<00:37,  1.87s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:20<00:35,  1.87s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [00:23<00:40,  2.24s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [00:23<00:30,  1.78s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [00:25<00:28,  1.81s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [00:27<00:27,  1.84s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [00:29<00:25,  1.85s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [00:31<00:24,  1.87s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [00:33<00:22,  1.88s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [00:35<00:20,  1.88s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [00:37<00:18,  1.89s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [00:39<00:17,  1.89s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [00:42<00:17,  2.25s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [00:42<00:12,  1.79s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [00:44<00:10,  1.82s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [00:46<00:09,  1.85s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [00:48<00:07,  1.86s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [00:50<00:05,  1.87s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [00:52<00:03,  1.88s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [00:54<00:01,  1.89s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [00:56<00:00,  1.87s/it]\u001b[A\n",
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]\n",
      "  3%|█▍                                          | 1/30 [00:05<02:38,  5.48s/it]\u001b[A\n",
      "  7%|██▉                                         | 2/30 [00:10<02:24,  5.15s/it]\u001b[A\n",
      " 10%|████▍                                       | 3/30 [00:12<01:39,  3.70s/it]\u001b[A\n",
      " 13%|█████▊                                      | 4/30 [00:17<01:48,  4.17s/it]\u001b[A\n",
      " 17%|███████▎                                    | 5/30 [00:22<01:50,  4.44s/it]\u001b[A\n",
      " 20%|████████▊                                   | 6/30 [00:27<01:51,  4.64s/it]\u001b[A\n",
      " 23%|██████████▎                                 | 7/30 [00:32<01:49,  4.77s/it]\u001b[A\n",
      " 27%|███████████▋                                | 8/30 [00:37<01:46,  4.85s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 9/30 [00:42<01:43,  4.91s/it]\u001b[A\n",
      " 33%|██████████████▎                            | 10/30 [00:47<01:39,  4.95s/it]\u001b[A\n",
      " 37%|███████████████▊                           | 11/30 [00:52<01:34,  4.98s/it]\u001b[A\n",
      " 40%|█████████████████▏                         | 12/30 [01:00<01:46,  5.92s/it]\u001b[A\n",
      " 43%|██████████████████▋                        | 13/30 [01:02<01:20,  4.74s/it]\u001b[A\n",
      " 47%|████████████████████                       | 14/30 [01:07<01:17,  4.83s/it]\u001b[A\n",
      " 50%|█████████████████████▌                     | 15/30 [01:12<01:13,  4.90s/it]\u001b[A\n",
      " 53%|██████████████████████▉                    | 16/30 [01:17<01:09,  4.94s/it]\u001b[A\n",
      " 57%|████████████████████████▎                  | 17/30 [01:22<01:04,  4.98s/it]\u001b[A\n",
      " 60%|█████████████████████████▊                 | 18/30 [01:27<01:00,  5.00s/it]\u001b[A\n",
      " 63%|███████████████████████████▏               | 19/30 [01:32<00:55,  5.02s/it]\u001b[A\n",
      " 67%|████████████████████████████▋              | 20/30 [01:37<00:50,  5.03s/it]\u001b[A\n",
      " 70%|██████████████████████████████             | 21/30 [01:42<00:45,  5.03s/it]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 22/30 [01:50<00:47,  5.96s/it]\u001b[A\n",
      " 77%|████████████████████████████████▉          | 23/30 [01:53<00:33,  4.77s/it]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 24/30 [01:58<00:29,  4.86s/it]\u001b[A\n",
      " 83%|███████████████████████████████████▊       | 25/30 [02:03<00:24,  4.92s/it]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 26/30 [02:08<00:19,  4.96s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████▋    | 27/30 [02:13<00:14,  4.98s/it]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 28/30 [02:18<00:10,  5.00s/it]\u001b[A\n",
      " 97%|█████████████████████████████████████████▌ | 29/30 [02:23<00:05,  5.02s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 30/30 [02:28<00:00,  4.95s/it]\u001b[A\n",
      "\n",
      "Total progress: 100%|███████████████████████████| 60/60 [03:36<00:00,  3.60s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "%cd \"{stable_diffusion_webui_path}\"\n",
    "\n",
    "# Code to set the options you want as defined in the very first block\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else ''\n",
    "theme = f'--theme {ui_theme}' if ui_theme else ''\n",
    "insecure_extension_access = '--enable-insecure-extension-access' if insecure_extension_access else ''\n",
    "queue = '--gradio-queue' if gradio_queue else ''\n",
    "\n",
    "# Launch args go below:\n",
    "logger.info(\"Launching A1111 WebUI\")\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} {theme} {queue}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef8381-eac8-4f04-a499-5b33b4dbd792",
   "metadata": {},
   "source": [
    "## Nuke Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa0168e7-e7d6-4e43-92c9-f29e5148cad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T13:33:31.169013Z",
     "iopub.status.busy": "2024-12-22T13:33:31.168646Z",
     "iopub.status.idle": "2024-12-22T13:33:34.328291Z",
     "shell.execute_reply": "2024-12-22T13:33:34.327068Z",
     "shell.execute_reply.started": "2024-12-22T13:33:31.168984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /storage/*\n",
    "!mv /notebooks/*.ipynb / # move the notebook out of the directory before we nuke it\n",
    "!rm -rf /notebooks/*\n",
    "!mv /*.ipynb /notebooks/ # move it back\n",
    "!rm -rf {model_storage_dir}\n",
    "!rm -rf {repo_storage_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b95c5-69ae-4f65-912b-109860b826e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
