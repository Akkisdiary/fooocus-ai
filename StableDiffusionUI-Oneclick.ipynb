{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2596b1a8-4c39-4a81-9a5a-c4565faad76f",
   "metadata": {},
   "source": [
    "## Python 3.10\n",
    "Python 3.10 is the recommended Python version for running the WebUI. Paperspace uses Python 3.9 for their containers so you must use a custom container. Luckily, I've created a container for you to use.\n",
    "First, delete your current notebook and create a new one following these instructions: https://docs.paperspace.com/gradient/notebooks/runtimes/#how-to-specify-a-custom-container\n",
    "Make sure to use this container image: `cyberes/gradient-base-py3.10`\n",
    "You can use the block below to test your Python version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a311c-b6b2-4fc2-8192-1facfe1402cf",
   "metadata": {},
   "source": [
    "#### Base Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ffc35-64a7-4de6-95f3-d3aeabc8cd9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T13:46:27.328321Z",
     "iopub.status.busy": "2024-12-22T13:46:27.327050Z",
     "iopub.status.idle": "2024-12-22T13:46:59.483747Z",
     "shell.execute_reply": "2024-12-22T13:46:59.482697Z",
     "shell.execute_reply.started": "2024-12-22T13:46:27.328257Z"
    }
   },
   "outputs": [],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd /notebooks\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s', level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def download_civit_model(url: str, output_path: str, token: str):\n",
    "\n",
    "    CHUNK_SIZE = 1638400\n",
    "    USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}',\n",
    "        'User-Agent': USER_AGENT,\n",
    "    }\n",
    "\n",
    "    # Disable automatic redirect handling\n",
    "    class NoRedirection(urllib.request.HTTPErrorProcessor):\n",
    "        def http_response(self, request, response):\n",
    "            return response\n",
    "        https_response = http_response\n",
    "\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener(NoRedirection)\n",
    "    response = opener.open(request)\n",
    "\n",
    "    if response.status in [301, 302, 303, 307, 308]:\n",
    "        redirect_url = response.getheader('Location')\n",
    "\n",
    "        # Extract filename from the redirect URL\n",
    "        parsed_url = urlparse(redirect_url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        content_disposition = query_params.get('response-content-disposition', [None])[0]\n",
    "\n",
    "        if content_disposition:\n",
    "            filename = unquote(content_disposition.split('filename=')[1].strip('\"'))\n",
    "        else:\n",
    "            raise Exception('Unable to determine filename')\n",
    "\n",
    "        response = urllib.request.urlopen(redirect_url)\n",
    "    elif response.status == 404:\n",
    "        raise Exception('File not found')\n",
    "    else:\n",
    "        raise Exception('No redirect found, something went wrong')\n",
    "\n",
    "    total_size = response.getheader('Content-Length')\n",
    "\n",
    "    if total_size is not None:\n",
    "        total_size = int(total_size)\n",
    "\n",
    "    if (Path(output_path)/filename).is_file():\n",
    "        logger.warn(f'{Path(output_path)/filename} already exists, skipping download')\n",
    "        return\n",
    "\n",
    "    output = Path(output_path)\n",
    "    output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(Path(output_path)/filename, 'wb') as f:\n",
    "        downloaded = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            chunk_start_time = time.time()\n",
    "            buffer = response.read(CHUNK_SIZE)\n",
    "            chunk_end_time = time.time()\n",
    "\n",
    "            if not buffer:\n",
    "                break\n",
    "\n",
    "            downloaded += len(buffer)\n",
    "            f.write(buffer)\n",
    "            chunk_time = chunk_end_time - chunk_start_time\n",
    "\n",
    "            if chunk_time > 0:\n",
    "                speed = len(buffer) / chunk_time / (1024 ** 2)  # Speed in MB/s\n",
    "\n",
    "            if total_size is not None:\n",
    "                progress = downloaded / total_size\n",
    "                sys.stdout.write(f'\\rDownloading: {filename} [{progress*100:.2f}%] - {speed:.2f} MB/s')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    hours, remainder = divmod(time_taken, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        time_str = f'{int(hours)}h {int(minutes)}m {int(seconds)}s'\n",
    "    elif minutes > 0:\n",
    "        time_str = f'{int(minutes)}m {int(seconds)}s'\n",
    "    else:\n",
    "        time_str = f'{int(seconds)}s'\n",
    "\n",
    "    sys.stdout.write('\\n')\n",
    "    logger.info(f'Download completed. File saved as: {Path(output_path)/filename}')\n",
    "    logger.info(f'Downloaded in {time_str}')\n",
    "\n",
    "\n",
    "def create_symlink(source, dest):\n",
    "    if dest.is_symlink() and not dest.exists():\n",
    "        logger.debug(f'Symlink broken, removing: {dest}')\n",
    "        dest.unlink()\n",
    "    if not dest.exists():\n",
    "        os.symlink(src, dest)\n",
    "    logger.info(f'{os.path.realpath(dest)} -> {dest}')\n",
    "\n",
    "def create_symlink_2(source, dest):\n",
    "    if os.path.isdir(dest):\n",
    "        dest = Path(dest, os.path.basename(source))\n",
    "    if not dest.exists():\n",
    "        os.symlink(source, dest)\n",
    "    logger.info(f'{source} -> {Path(dest).absolute()}')\n",
    "\n",
    "\n",
    "def clone_repo(dest, remote, branch):\n",
    "    if not (dest / '.git').exists():\n",
    "        # It's possible that the repo already exists but the repo has not been downloaded.\n",
    "        # We will init the repo manually.\n",
    "        !mkdir -p \"{dest}\"\n",
    "        %cd \"{dest}\"\n",
    "        !git init\n",
    "        !git remote add origin \"{remote}\"\n",
    "        !git fetch origin \"{branch}\"\n",
    "        !git checkout -t \"origin/{branch}\" -f\n",
    "    else:\n",
    "        logger.debug(f'{dest} already downloaded, updating...')\n",
    "        !cd \"{dest}\" && git pull origin \"{branch}\" # no % so we don't interfere with the main process\n",
    "\n",
    "\n",
    "def download_whl(url, binary_name='xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl'):\n",
    "    tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "    !wget \"{url}\" -O \"{tmp_dir}/{binary_name}\"\n",
    "    return os.path.join(tmp_dir, binary_name)\n",
    "\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    for file in Path(dir).iterdir():\n",
    "        if file.is_symlink() and not file.exists():\n",
    "            logger.debug(f'Symlink broken, removing: {file}')\n",
    "            file.unlink()\n",
    "\n",
    "\n",
    "def link_ckpts(source_path, webui_sd_model_path):\n",
    "    # Link .ckpt and .safetensor/.st files (recursive)\n",
    "    logger.info(f'Linking .ckpt and .safetensor/.safetensors/.st files in {source_path}')\n",
    "    source_path = Path(source_path)\n",
    "    for file in [\n",
    "        p for p in source_path.rglob('*')\n",
    "        if p.suffix in ['.ckpt', '.safetensor', '.safetensors', '.st']\n",
    "    ]:\n",
    "        if Path(file).parent.parts[-1] not in ['hypernetworks', 'vae', 'embeddings'] :\n",
    "            if not (webui_sd_model_path / file.name):\n",
    "                logger.debug(f'New model: {file.name}')\n",
    "            create_symlink_2(file, webui_sd_model_path)\n",
    "    # Link config yaml files\n",
    "    logger.info(f'Linking config .yaml files in {source_path}')\n",
    "    for file in source_path.glob('*.yaml'):\n",
    "        create_symlink_2(file, webui_sd_model_path)\n",
    "\n",
    "\n",
    "def install_xformers(install_pip_xformers):\n",
    "    if install_pip_xformers:\n",
    "        logger.info('Installing xformers through pip...')\n",
    "        !pip install --no-dependencies xformers\n",
    "    else:\n",
    "        xformers_whl = None\n",
    "        found_xformers_whls = glob('/notebooks/xformers-*')\n",
    "        if len(found_xformers_whls) == 1:\n",
    "            logger.info('Installing xformers using your pre-built wheel...')\n",
    "            xformers_whl = found_xformers_whls[0]\n",
    "            delete_whl = False\n",
    "        elif len(found_xformers_whls) > 1:\n",
    "            logger.info('Found more than one Xformers wheel in /notebooks so not doing anything!')\n",
    "        else:\n",
    "            logger.info('Installing xformers from wheels on Github...')\n",
    "            delete_whl = True\n",
    "\n",
    "            # Set up pip packages\n",
    "            !pip uninstall -y torch torchvision torchaudio protobuf # Remove existing pytorch install.\n",
    "            # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # Install pytorch for cuda 11.3\n",
    "            s = subprocess.getoutput('nvidia-smi -L')\n",
    "            logger.info(f'Your SMI: {s}')\n",
    "            if 'A4000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/raw/main/a4000/xformers-0.0.18%2Bda27862.d20230413-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A5000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A6000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'P5000' in s:\n",
    "                xformers_whl = download_whl('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/p5000/xformers-0.0.16%2B6f3c20f.d20230127-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 4000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 5000' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A100' in s:\n",
    "                xformers_whl = download_whl('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'M4000' in s:\n",
    "                logger.warning('xformers for M4000 hasn\\'t been built yet.')\n",
    "                # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            else:\n",
    "                logger.warning('GPU not matched to xformers binary so a one-size-fits-all binary was installed. If you have any issues, please build xformers using the Tools block below.')\n",
    "                xformers_whl = download_whl('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "        if xformers_whl:\n",
    "            !pip uninstall -y xformers\n",
    "            # We're going to install xformers without installing any of its dependencies since they should already be installed.\n",
    "            # If you have any issues then replacing --no-dependencies with --force-reinstall\n",
    "            !pip install --no-dependencies \"{xformers_whl}\"\n",
    "            if delete_whl:\n",
    "                !rm -rf \"{xformers_whl}\"\n",
    "\n",
    "\n",
    "py_version = sys.version.split(' ')[0]\n",
    "if int(py_version.split('.')[1]) < 10:\n",
    "    logger.info(f'Your Python version is less than 3.10 -> {py_version}')\n",
    "else:\n",
    "    logger.info(f'Your Python version is good: {py_version}')\n",
    "\n",
    "# Other optional settings\n",
    "# You don't have to change these if you don't want to.\n",
    "symlink_to_notebooks = True                            # Enables the creation of symlinks back to /notebooks/\n",
    "activate_xformers = True                               # Enables the xformers optimizations using pre-built wheels.\n",
    "                                                       # Setting to True will automatically set up your environment/machine for xformers. \n",
    "install_pip_xformers = False                           # Install xformers through pip. Probably won't work because it needs Torch 2.0\n",
    "link_novelai_anime_vae = True                          # Enables the linking of animevae.pt to each of the NovelAI models.\n",
    "                                                       # Set to True if you've downloaded both the NovelAI models and hypernetworks.\n",
    "activate_deepdanbooru = False                          # Enable and install DeepDanbooru -> https://github.com/KichangKim/DeepDanbooru\n",
    "activate_medvram = True                                # Enable medvram option.\n",
    "                                                       # These are model optimizations which will reduce VRAM usage at the expense of some speed.\n",
    "                                                       # Set to False if you have a lot of VRAM.\n",
    "disable_pickle_check = False                           # Disable the automatic check for unexpected data in model files.\n",
    "                                                       # Leave this set to False unless you have a reason to disable the check.\n",
    "gradio_port = False                                    # Launch Gradio on a specific port. Set to False to let Gradio choose a port.\n",
    "                                                       # This disables online Gradio app mode and you will only be able to access it on your local network.\n",
    "gradio_auth = False                                    # Enable gradio_auth and insecure-extension-access option.\n",
    "                                                       # Set to a username:password (for example: \"me:password\") to enable.\n",
    "search_paperspace_datasets = True                      # Enable searching for checkpoints in /datasets to link to the webui\n",
    "ui_theme = None                                        # Set the WEB UI theme. Values can be None (default) or 'dark'.\n",
    "insecure_extension_access = False                      # Force enable extensions without a password.\n",
    "                                                       # If you don't set a password anyone can install and run arbitrary code on your machine!\n",
    "                                                       # Instead, use gradio_auth which will automatically enable extensions when set.\n",
    "gradio_queue = False                                   # Uses gradio queue; experimental option; breaks restart UI button.\n",
    "civitai_token = input('Your CivitAI Token? ')\n",
    "\n",
    "# Choose where to store your model checkpoints.\n",
    "model_storage_dir = '/tmp/stable-diffusion-models' # Free Tier\n",
    "# model_storage_dir = '/storage/models' # Paid Tier\n",
    "\n",
    "# Optional path settings\n",
    "repo_storage_dir = '/storage/stable-diffusion'         # Where to store your Stable Diffusion-related files.\n",
    "export_storage_dir = '/notebooks/exports'              # Where the generated images will be exported to.\n",
    "pip_cache_dir = None                                   # The installer can cache pip wheels so you don't have to re-download them\n",
    "                                                       # every time you start the machine. I recommed setting it to '/storage/pip/cache'\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "model_storage_dir = Path(model_storage_dir)\n",
    "stable_diffusion_webui_path = repo_storage_dir / 'stable-diffusion-webui'\n",
    "\n",
    "!mkdir -p \"{stable_diffusion_webui_path / 'outputs'}\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path / 'log'}\"\n",
    "\n",
    "symlinks = [\n",
    "    (stable_diffusion_webui_path, Path('/notebooks/stable-diffusion-webui')),\n",
    "    (stable_diffusion_webui_path / 'outputs', Path('/notebooks/outputs')),\n",
    "    # (stable_diffusion_webui_path / 'log', repo_storage_dir / 'stable-diffusion-webui' / 'outputs' / 'log'),\n",
    "    (Path('/storage'), Path('/notebooks/storage')),\n",
    "    (model_storage_dir, Path('/notebooks/models')),\n",
    "]\n",
    "if symlink_to_notebooks and repo_storage_dir != '/notebooks':\n",
    "    logger.info('Creating Symlinks...')\n",
    "    for src, dest in symlinks:\n",
    "        create_symlink(src, dest)\n",
    "\n",
    "clone_repo(stable_diffusion_webui_path, \"https://github.com/AUTOMATIC1111/stable-diffusion-webui\", \"master\")\n",
    "\n",
    "extensions = [\n",
    "    \"https://github.com/Bing-su/adetailer\",\n",
    "    \"https://github.com/DominikDoom/a1111-sd-webui-tagcomplete\"\n",
    "]\n",
    "for url in extensions:\n",
    "    name = url.split['/'][-1]\n",
    "    clone_repo(stable_diffusion_webui_path/f'extensions/{name}', url, \"main\")\n",
    "\n",
    "# Make sure important directories exists\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{model_storage_dir}/vae\"\n",
    "!mkdir -p \"{model_storage_dir}/embeddings\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/models/hypernetworks\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/models/VAE\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/models/Lora\"\n",
    "!mkdir -p \"{stable_diffusion_webui_path}/log/images\"\n",
    "\n",
    "if not model_storage_dir.exists():\n",
    "    logger.error(f'Your model storage directory does not exist: {model_storage_dir}')\n",
    "    sys.exit(1)\n",
    "\n",
    "# ===================================================================================================\n",
    "# Save variables to Jupiter's temp storage so we can access it even if the kernel restarts.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir export_storage_dir activate_xformers link_novelai_anime_vae activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth search_paperspace_datasets ui_theme insecure_extension_access pip_cache_dir gradio_queue install_pip_xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f61c44",
   "metadata": {},
   "source": [
    "## Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eca8b-bb4e-479e-aa7a-379e53fa8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd \"{stable_diffusion_webui_path}\"\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade wheel setuptools\n",
    "\n",
    "if activate_xformers:\n",
    "    install_xformers(install_pip_xformers)\n",
    "\n",
    "import launch; launch.prepare_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c309a",
   "metadata": {},
   "source": [
    "## Download Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e60e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "civit_models = [\n",
    "    \"https://civitai.com/api/download/models/474400\", # zovya_photoreal\n",
    "    \"https://civitai.com/api/download/models/261539?type=Model&format=SafeTensor&size=pruned&fp=fp16\", # Analog Madness - Realistic Model - Full fp16\n",
    "    \"https://civitai.com/api/download/models/501240?type=Model&format=SafeTensor&size=pruned&fp=fp16\", # A-Zovya Photoreal\n",
    "]\n",
    "for url in civit_models:\n",
    "    logger.debug(f'Downloading Embedding {url} into {model_storage_dir}')\n",
    "    download_civit_model(url, model_storage_dir, civitai_token)\n",
    "\n",
    "civit_embeddings = [\n",
    "    \"https://civitai.com/api/download/models/253081\", # Inna Nobody\n",
    "]\n",
    "for url in civit_embeddings:\n",
    "    dest = model_storage_dir/'embeddings'\n",
    "    logger.debug(f'Downloading Embedding {url} into {dest}')\n",
    "    download_civit_model(url, dest, civitai_token)\n",
    "\n",
    "civit_loras = [\n",
    "    \"https://civitai.com/api/download/models/53221?type=Model&format=SafeTensor\", #Better Portrait Lighting\n",
    "]\n",
    "for url in civit_loras:\n",
    "    dest = model_storage_dir/'Lora'\n",
    "    logger.debug(f'Downloading Embedding {url} into {dest}')\n",
    "    download_civit_model(url, dest, civitai_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5b70c",
   "metadata": {},
   "source": [
    "## Link Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398faac-1687-46b0-bb8b-e33d2c9eef44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:28:17.045927Z",
     "iopub.status.busy": "2024-12-22T14:28:17.045367Z",
     "iopub.status.idle": "2024-12-22T14:28:43.712024Z",
     "shell.execute_reply": "2024-12-22T14:28:43.711045Z",
     "shell.execute_reply.started": "2024-12-22T14:28:17.045884Z"
    }
   },
   "outputs": [],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd \"{stable_diffusion_webui_path}\"\n",
    "\n",
    "webui_root_model_path = Path(stable_diffusion_webui_path, 'models')\n",
    "webui_sd_model_path = Path(webui_root_model_path, 'Stable-diffusion')\n",
    "webui_hypernetwork_path = Path(webui_root_model_path, 'hypernetworks')\n",
    "webui_vae_path = Path(webui_root_model_path, 'VAE')\n",
    "webui_lora_model_path = Path(webui_root_model_path, 'Lora')\n",
    "webui_embeddings_path = Path(stable_diffusion_webui_path, 'embeddings')\n",
    "\n",
    "# Check for broken symlinks and remove them\n",
    "logger.info('Removing broken symlinks...')\n",
    "delete_broken_symlinks(webui_sd_model_path)\n",
    "delete_broken_symlinks(webui_hypernetwork_path)\n",
    "delete_broken_symlinks(webui_vae_path)\n",
    "delete_broken_symlinks(webui_lora_model_path)\n",
    "delete_broken_symlinks(webui_embeddings_path)\n",
    "\n",
    "logger.info('Linking checkpoints...')\n",
    "link_ckpts(model_storage_dir, webui_sd_model_path)\n",
    "\n",
    "# Link hypernetworks\n",
    "logger.info('Linking hypernetworks...')\n",
    "hypernetwork_source_path = Path(model_storage_dir, 'hypernetworks')\n",
    "if hypernetwork_source_path.is_dir():\n",
    "    for file in hypernetwork_source_path.iterdir():\n",
    "        create_symlink_2(hypernetwork_source_path / file, webui_hypernetwork_path)\n",
    "else:\n",
    "    logger.warning(f'Hypernetwork storage directory not found: {hypernetwork_source_path}')\n",
    "\n",
    "# Link VAEs\n",
    "logger.info('Linking VAEs...')\n",
    "vae_source_path = Path(model_storage_dir, 'vae')\n",
    "if vae_source_path.is_dir():\n",
    "    for file in vae_source_path.iterdir():\n",
    "        create_symlink_2(vae_source_path / file, webui_vae_path)\n",
    "else:\n",
    "    logger.warning(f'VAE storage directory not found: {vae_source_path}')\n",
    "\n",
    "# Link Lora\n",
    "logger.info('Linking Loras...')\n",
    "lora_source_path = Path(model_storage_dir, 'Lora')\n",
    "if lora_source_path.is_dir():\n",
    "    for file in lora_source_path.iterdir():\n",
    "        create_symlink_2(lora_source_path / file, webui_lora_model_path)\n",
    "else:\n",
    "    logger.warning(f'Lora storage directory not found: {lora_source_path}')\n",
    "\n",
    "# Link Embeddings\n",
    "logger.info('Linking Embeddings...')\n",
    "embeddings_source_path = Path(model_storage_dir, 'embeddings')\n",
    "if embeddings_source_path.is_dir():\n",
    "    for file in embeddings_source_path.iterdir():\n",
    "        create_symlink_2(embeddings_source_path / file, webui_embeddings_path)\n",
    "else:\n",
    "    logger.warning(f'Embeddings storage directory not found: {embeddings_source_path}')\n",
    "\n",
    "\n",
    "if search_paperspace_datasets:\n",
    "    if Path('/datasets').is_dir():\n",
    "        link_ckpts('/datasets', webui_sd_model_path)\n",
    "    else:\n",
    "        logger.warning('No datasets mounted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a4a11e",
   "metadata": {},
   "source": [
    "## Start A1111 Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0d67b-887e-40fb-9ce0-2aa1d13efb9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T14:32:36.515999Z",
     "iopub.status.busy": "2024-12-22T14:32:36.515004Z",
     "iopub.status.idle": "2024-12-22T14:40:32.114095Z",
     "shell.execute_reply": "2024-12-22T14:40:32.112926Z",
     "shell.execute_reply.started": "2024-12-22T14:32:36.515938Z"
    }
   },
   "outputs": [],
   "source": [
    "!export PIP_ROOT_USER_ACTION=ignore\n",
    "%cd \"{stable_diffusion_webui_path}\"\n",
    "\n",
    "# Code to set the options you want as defined in the very first block\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else ''\n",
    "theme = f'--theme {ui_theme}' if ui_theme else ''\n",
    "insecure_extension_access = '--enable-insecure-extension-access' if insecure_extension_access else ''\n",
    "queue = '--gradio-queue' if gradio_queue else ''\n",
    "\n",
    "# Launch args go below:\n",
    "logger.info(\"Launching A1111 WebUI\")\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} {theme} {queue}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c401a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ef8381-eac8-4f04-a499-5b33b4dbd792",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">- Nuke Machine -</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0168e7-e7d6-4e43-92c9-f29e5148cad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T13:33:31.169013Z",
     "iopub.status.busy": "2024-12-22T13:33:31.168646Z",
     "iopub.status.idle": "2024-12-22T13:33:34.328291Z",
     "shell.execute_reply": "2024-12-22T13:33:34.327068Z",
     "shell.execute_reply.started": "2024-12-22T13:33:31.168984Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf /storage/*\n",
    "!mv /notebooks/*.ipynb / # move the notebook out of the directory before we nuke it\n",
    "!rm -rf /notebooks/*\n",
    "!mv /*.ipynb /notebooks/ # move it back\n",
    "!rm -rf {model_storage_dir}\n",
    "!rm -rf {repo_storage_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b95c5-69ae-4f65-912b-109860b826e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
