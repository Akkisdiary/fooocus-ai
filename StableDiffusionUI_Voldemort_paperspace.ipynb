{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfKvWAVnz8OB",
    "tags": []
   },
   "source": [
    "# AUTOMATIC1111's Stable Diffusion WebUI\n",
    "\n",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "\n",
    "Loosely based on https://colab.research.google.com/drive/1kw3egmSn-KgWsikYvOMjJkVDsPLjEMzl\n",
    "\n",
    "**Guides**\n",
    "- [Getting started on Paperspace](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/blob/main/Docs/Paperspace%20Guide%20for%20Retards.md)\n",
    "- [Using the WebUI](https://rentry.org/voldy)\n",
    "- [Using the Inpainter](https://rentry.org/drfar)\n",
    "- [Textual Inversion](https://rentry.org/aikgx)\n",
    "- [Crowd-Sourced Prompts](https://lexica.art/)\n",
    "- [Artist Name Prompts](https://sgreens.notion.site/sgreens/4ca6f4e229e24da6845b6d49e6b08ae7?v=fdf861d1c65d456e98904fe3f3670bd3)\n",
    "- [Stable Diffusion Models](https://cyberes.github.io/stable-diffusion-models)\n",
    "- [Textual Inversion Models](https://cyberes.github.io/stable-diffusion-textual-inversion-models/)\n",
    "- [Have I Been Trained?](https://haveibeentrained.com/)\n",
    "\n",
    "<br>\n",
    "\n",
    "Did I break something with a new update? You can download an old version of this notebook here: https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/commits/master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation and Setup\n",
    "\n",
    "You must reinstall everything each time you restart the machine. If already downloaded, dependencies will be auto-updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Where to store your files**\n",
    "\n",
    "`/storage/` is persistent storage shared across all machines on your account. Mounted to your machine.\n",
    "\n",
    "`/notebooks/` is storage for this notebook only. This directory has to be copied into your machine which can increase start/stop times if it's very large. To avoid this, put large files in `/storage/`.\n",
    "\n",
    "`/tmp/` <mark style=\"background-color:lime\">is not a persistent directory, meaning your files there will be deleted when the machine turns off.</mark>\n",
    "\n",
    "<br>\n",
    "\n",
    "<mark style=\"background-color: #ff780082\">If you are having storage issues</mark>, set `repo_storage_dir` to `/tmp/stable-diffusion`. Make sure `symlink_to_notebooks` is set to `True` so it gets linked back to `/notebooks/`.\n",
    "\n",
    "<br>\n",
    "\n",
    "<mark>You must uncomment the correct section and run the block below or else the notebook won't work!</mark>\n",
    "\n",
    "Select the section you want and do `ctrl + /` to uncomment. If you change any settings here, rerun this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:28:26.447518Z",
     "iopub.status.busy": "2024-12-22T07:28:26.447117Z",
     "iopub.status.idle": "2024-12-22T07:28:26.465681Z",
     "shell.execute_reply": "2024-12-22T07:28:26.464952Z",
     "shell.execute_reply.started": "2024-12-22T07:28:26.447490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'symlink_to_notebooks' (bool)\n",
      "Stored 'model_storage_dir' (str)\n",
      "Stored 'repo_storage_dir' (str)\n",
      "Stored 'export_storage_dir' (str)\n",
      "Stored 'activate_xformers' (bool)\n",
      "Stored 'link_novelai_anime_vae' (bool)\n",
      "Stored 'activate_deepdanbooru' (bool)\n",
      "Stored 'activate_medvram' (bool)\n",
      "Stored 'disable_pickle_check' (bool)\n",
      "Stored 'gradio_port' (bool)\n",
      "Stored 'gradio_auth' (bool)\n",
      "Stored 'search_paperspace_datasets' (bool)\n",
      "Stored 'ui_theme' (NoneType)\n",
      "Stored 'insecure_extension_access' (bool)\n",
      "Stored 'pip_cache_dir' (NoneType)\n",
      "Stored 'gradio_queue' (bool)\n",
      "Stored 'install_pip_xformers' (bool)\n"
     ]
    }
   ],
   "source": [
    "# Choose where to store your model checkpoints.\n",
    "\n",
    "# Free Tier\n",
    "model_storage_dir = '/tmp/stable-diffusion-models'\n",
    "\n",
    "# Paid Tier\n",
    "# model_storage_dir = '/storage/models'\n",
    "\n",
    "\n",
    "\n",
    "# Optional path settings\n",
    "repo_storage_dir = '/storage/stable-diffusion'         # Where to store your Stable Diffusion-related files.\n",
    "\n",
    "export_storage_dir = '/notebooks/exports'              # Where the generated images will be exported to.\n",
    "\n",
    "pip_cache_dir = None                                   # The installer can cache pip wheels so you don't have to re-download them\n",
    "                                                       # every time you start the machine. I recommed setting it to '/storage/pip/cache'\n",
    "\n",
    "\n",
    "# Other optional settings\n",
    "# You don't have to change these if you don't want to.\n",
    "\n",
    "symlink_to_notebooks = True                            # Enables the creation of symlinks back to /notebooks/\n",
    "\n",
    "activate_xformers = True                               # Enables the xformers optimizations using pre-built wheels.\n",
    "                                                       # Setting to True will automatically set up your environment/machine for xformers. \n",
    "\n",
    "link_novelai_anime_vae = True                          # Enables the linking of animevae.pt to each of the NovelAI models.\n",
    "                                                       # Set to True if you've downloaded both the NovelAI models and hypernetworks.\n",
    "\n",
    "activate_deepdanbooru = False                          # Enable and install DeepDanbooru -> https://github.com/KichangKim/DeepDanbooru\n",
    "\n",
    "activate_medvram = True                                # Enable medvram option.\n",
    "                                                       # These are model optimizations which will reduce VRAM usage at the expense of some speed.\n",
    "                                                       # Set to False if you have a lot of VRAM.\n",
    "\n",
    "disable_pickle_check = False                           # Disable the automatic check for unexpected data in model files.\n",
    "                                                       # Leave this set to False unless you have a reason to disable the check.\n",
    "\n",
    "gradio_port = False                                    # Launch Gradio on a specific port. Set to False to let Gradio choose a port.\n",
    "                                                       # This disables online Gradio app mode and you will only be able to access it on your local network.\n",
    "\n",
    "gradio_auth = False                                    # Enable gradio_auth and insecure-extension-access option.\n",
    "                                                       # Set to a username:password (for example: \"me:password\") to enable.\n",
    "\n",
    "search_paperspace_datasets = True                      # Enable searching for checkpoints in /datasets to link to the webui\n",
    "\n",
    "ui_theme = None                                        # Set the WEB UI theme. Values can be None (default) or 'dark'.\n",
    "\n",
    "insecure_extension_access = False                      # Force enable extensions without a password.\n",
    "                                                       # If you don't set a password anyone can install and run arbitrary code on your machine!\n",
    "                                                       # Instead, use gradio_auth which will automatically enable extensions when set.\n",
    "\n",
    "gradio_queue = False                                   # Uses gradio queue; experimental option; breaks restart UI button.\n",
    "\n",
    "install_pip_xformers = True                           # Install xformers through pip. Probably won't work because it needs Torch 2.0\n",
    "\n",
    "\n",
    "# ===================================================================================================\n",
    "# Save variables to Jupiter's temp storage so we can access it even if the kernel restarts.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir export_storage_dir activate_xformers link_novelai_anime_vae activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth search_paperspace_datasets ui_theme insecure_extension_access pip_cache_dir gradio_queue install_pip_xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>If you see any errors please check your settings!</mark>\n",
    "\n",
    "**Don't forget, there's a [block in the Tools section](#Download-the-latest-version-of-this-notebook-from-Github) at the bottom to update this notebook to [the latest version](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/blob/main/StableDiffusionUI_Voldemort_paperspace.ipynb) on GitHub.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clone the WebUI repository\n",
    "\n",
    "If you get an error that says something like \"fatal: destination path already exists and is not an empty directory\", the `.git` folder is missing. Please delete `repo_storage_dir/stable-diffusion-webui` and reinstall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:28:33.766511Z",
     "iopub.status.busy": "2024-12-22T07:28:33.766109Z",
     "iopub.status.idle": "2024-12-22T07:28:35.957181Z",
     "shell.execute_reply": "2024-12-22T07:28:35.955964Z",
     "shell.execute_reply.started": "2024-12-22T07:28:33.766460Z"
    },
    "id": "sBbcB4vwj_jm",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stable-diffusion-webui already downloaded, updating...\n",
      "Already up to date.\n",
      "\n",
      "Creating Symlinks...\n",
      "/storage/stable-diffusion/stable-diffusion-webui -> /notebooks/stable-diffusion-webui\n",
      "/storage/stable-diffusion/stable-diffusion-webui/outputs -> /notebooks/outputs\n",
      "/storage/stable-diffusion/stable-diffusion-webui/log -> /storage/stable-diffusion/stable-diffusion-webui/outputs/log\n",
      "/storage -> /notebooks/storage\n",
      "Symlink broken, removing: /notebooks/models\n",
      "/tmp/stable-diffusion-models -> /notebooks/models\n"
     ]
    }
   ],
   "source": [
    "# You'll see this little code block at the beginning of every cell.\n",
    "# It makes sure you have ran the first block that defines your settings.\n",
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir\n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "    \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "stable_diffusion_webui_path = repo_storage_dir / 'stable-diffusion-webui'\n",
    "\n",
    "if not (stable_diffusion_webui_path / '.git').exists():    \n",
    "    # It's possible that the stable_diffusion_webui_path already exists but the repo has not been downloaded.\n",
    "    # We will init the repo manually.\n",
    "    !mkdir -p \"{stable_diffusion_webui_path}\"\n",
    "    %cd \"{stable_diffusion_webui_path}\"\n",
    "    !git init\n",
    "    !git remote add origin https://github.com/AUTOMATIC1111/stable-diffusion-webui\n",
    "    !git fetch\n",
    "    !git checkout -t origin/master -f\n",
    "    # !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui \"{stable_diffusion_webui_path}\"\n",
    "else:\n",
    "    print('stable-diffusion-webui already downloaded, updating...')\n",
    "    !cd \"{stable_diffusion_webui_path}\" && git pull # no % so we don't interfere with the main process\n",
    "\n",
    "\n",
    "!mkdir -p \"{repo_storage_dir / 'stable-diffusion-webui' / 'outputs'}\"\n",
    "!mkdir -p \"{repo_storage_dir / 'stable-diffusion-webui' / 'log'}\"\n",
    "\n",
    "symlinks = [\n",
    "    (repo_storage_dir / 'stable-diffusion-webui', Path('/notebooks/stable-diffusion-webui')),\n",
    "    (repo_storage_dir / 'stable-diffusion-webui' / 'outputs', Path('/notebooks/outputs')),\n",
    "    (repo_storage_dir / 'stable-diffusion-webui' / 'log', repo_storage_dir / 'stable-diffusion-webui' / 'outputs' / 'log'),\n",
    "    (Path('/storage'), Path('/notebooks/storage')),\n",
    "    (Path(model_storage_dir), Path('/notebooks/models')),\n",
    "]\n",
    "\n",
    "if symlink_to_notebooks and repo_storage_dir != '/notebooks':\n",
    "    print('\\nCreating Symlinks...')\n",
    "    for src, dest in symlinks:\n",
    "        # If `/notebooks/stable-diffusion-webui` is a broken symlink then remove it.\n",
    "        # The WebUI might have previously been installed in a non-persistent directory.\n",
    "        if dest.is_symlink() and not dest.exists(): # .exists() validates a symlink\n",
    "            print('Symlink broken, removing:', dest)\n",
    "            dest.unlink()\n",
    "        if not dest.exists():\n",
    "            os.symlink(src, dest)\n",
    "        print(os.path.realpath(dest), '->', dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Python 3.10\n",
    "\n",
    "Python 3.10 is the recommended Python version for running the WebUI. Paperspace uses Python 3.9 for their containers so you must use a custom container. Luckily, I've created a container for you to use.\n",
    "\n",
    "First, delete your current notebook and create a new one following these instructions: https://docs.paperspace.com/gradient/notebooks/runtimes/#how-to-specify-a-custom-container\n",
    "\n",
    "Make sure to use this container image: `cyberes/gradient-base-py3.10`\n",
    "\n",
    "You can use the block below to test your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:30:25.561017Z",
     "iopub.status.busy": "2024-12-22T07:30:25.560175Z",
     "iopub.status.idle": "2024-12-22T07:30:25.566917Z",
     "shell.execute_reply": "2024-12-22T07:30:25.565715Z",
     "shell.execute_reply.started": "2024-12-22T07:30:25.560990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Python version is good: 3.10.10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "version = sys.version.split(' ')[0]\n",
    "v_parts = version.split('.')\n",
    "if int(v_parts[1]) < 10:\n",
    "    print(f'Your Python version is less than 3.10 -> {version}')\n",
    "else:\n",
    "    print('Your Python version is good:', version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the special Python 3.10 container *cyberes/gradient-base-py3.10:latest* you need to either install xformers through pip or build them yourself.\n",
    "\n",
    "First, try installing it through pip by setting `install_pip_xformers = True` in the settings block above. If that fails or you encounter issues, use the block in the Tools section to build xformers for your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C68TUpkq0nj_",
    "tags": []
   },
   "source": [
    "## Install requirements and download repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:30:31.167263Z",
     "iopub.status.busy": "2024-12-22T07:30:31.166929Z",
     "iopub.status.idle": "2024-12-22T07:33:16.817508Z",
     "shell.execute_reply": "2024-12-22T07:33:16.816485Z",
     "shell.execute_reply.started": "2024-12-22T07:30:31.167238Z"
    },
    "id": "SaAJk33ppFw1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/stable-diffusion/stable-diffusion-webui\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.0.1\n",
      "    Uninstalling pip-23.0.1:\n",
      "      Successfully uninstalled pip-23.0.1\n",
      "Successfully installed pip-24.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.35.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.6.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.35.1\n",
      "    Uninstalling wheel-0.35.1:\n",
      "      Successfully uninstalled wheel-0.35.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 67.6.0\n",
      "    Uninstalling setuptools-67.6.0:\n",
      "      Successfully uninstalled setuptools-67.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradient-utils 0.5.0 requires wheel<0.36.0,>=0.35.1, but you have wheel 0.45.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-75.6.0 wheel-0.45.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: torch 1.12.1+cu116\n",
      "Uninstalling torch-1.12.1+cu116:\n",
      "  Successfully uninstalled torch-1.12.1+cu116\n",
      "Found existing installation: torchvision 0.13.1+cu116\n",
      "Uninstalling torchvision-0.13.1+cu116:\n",
      "  Successfully uninstalled torchvision-0.13.1+cu116\n",
      "Found existing installation: torchaudio 0.12.1+cu116\n",
      "Uninstalling torchaudio-0.12.1+cu116:\n",
      "  Successfully uninstalled torchaudio-0.12.1+cu116\n",
      "Found existing installation: protobuf 3.19.6\n",
      "Uninstalling protobuf-3.19.6:\n",
      "  Successfully uninstalled protobuf-3.19.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mPython 3.10.10 (main, Feb  8 2023, 14:50:01) [GCC 9.4.0]\n",
      "Version: v1.10.1\n",
      "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
      "Installing torch and torchvision\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.1.2\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.2%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 GB 27.5 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.16.2\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.2%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 127.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (4.5.0)\n",
      "Collecting sympy (from torch==2.1.2)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2) (2023.3.0)\n",
      "Collecting triton==2.1.0 (from torch==2.1.2)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.2/89.2 MB 132.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (1.23.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.2) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision==0.16.2) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.2) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision==0.16.2) (2019.11.28)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 43.0 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 114.6 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, triton, sympy, torch, torchvision\n",
      "Successfully installed mpmath-1.3.0 sympy-1.13.3 torch-2.1.2+cu121 torchvision-0.16.2+cu121 triton-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing clip\n",
      "Installing open_clip\n",
      "Installing requirements\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.28.2)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.5.1)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting markdownify\n",
      "  Downloading markdownify-0.14.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
      "Collecting six (from gdown)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading markdownify-0.14.1-py3-none-any.whl (11 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, markdownify, bs4\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
      "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bs4-0.0.2 markdownify-0.14.1 six-1.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling xformers through pip...\n",
      "Collecting xformers\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xformers\n",
      "Successfully installed xformers-0.0.28.post3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "===================================\n",
      "Done! If you're seeing this the process has exited successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru pip_cache_dir install_pip_xformers\n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, pip_cache_dir, install_pip_xformers]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade wheel setuptools\n",
    "\n",
    "if pip_cache_dir:\n",
    "    !pip install git+https://github.com/pixelb/crudini.git\n",
    "    !mkdir -p \"{pip_cache_dir}\"\n",
    "    !python3 -m crudini --set /etc/pip.conf global cache-dir \"{pip_cache_dir}\"\n",
    "    !echo \"Set pip cache directory: $(pip cache dir)\"\n",
    "\n",
    "# Uninstall PyTorch and some other libraries so the WebUI can install the versions it needs\n",
    "!pip uninstall -y torch torchvision torchaudio protobuf\n",
    "\n",
    "# Import launch.py which will automatically run the install script but not launch the WebUI.\n",
    "import launch\n",
    "launch.prepare_environment()\n",
    "\n",
    "# Install things for this notebook\n",
    "!pip install requests gdown bs4 markdownify\n",
    "\n",
    "# The installer isn't installing deepdanbooru right now so we'll do it manually.\n",
    "if activate_deepdanbooru:\n",
    "    # https://github.com/KichangKim/DeepDanbooru/releases\n",
    "    !pip install \"git+https://github.com/KichangKim/DeepDanbooru.git@v3-20211112-sgd-e28#egg=deepdanbooru[tensorflow]\" # $(curl --silent \"https://api.github.com/KichangKim/DeepDanbooru/releases/latest\" | grep '\"tag_name\":' | sed -E 's/.*\"([^\"]+)\".*/\\1/')#egg=deepdanbooru[tensorflow]\" # tensorflow==2.10.0 tensorflow-io==0.27.0 flatbuffers==1.12\n",
    "\n",
    "# We need to install xformers first so that the WebUI installer can install the correct version of PyTorch afterwards\n",
    "if activate_xformers:\n",
    "    if install_pip_xformers:\n",
    "        print('Installing xformers through pip...')\n",
    "        !pip install --no-dependencies xformers\n",
    "    else:\n",
    "        import subprocess\n",
    "        from glob import glob\n",
    "        def download_release(url, binary_name='xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl'):\n",
    "            tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "            !wget \"{url}\" -O \"{tmp_dir}/{binary_name}\"\n",
    "            return os.path.join(tmp_dir, binary_name)\n",
    "\n",
    "        xformers_whl = None\n",
    "        found_xformers_whls = glob('/notebooks/xformers-*')\n",
    "        if len(found_xformers_whls) == 1:\n",
    "            print('Installing xformers using your pre-built wheel...')\n",
    "            xformers_whl = found_xformers_whls[0]\n",
    "            delete_whl = False\n",
    "        elif len(found_xformers_whls) > 1:\n",
    "            print('Found more than one Xformers wheel in /notebooks so not doing anything!')\n",
    "        else:\n",
    "            print('Installing xformers from wheels on Github...')\n",
    "            delete_whl = True\n",
    "            # Set up pip packages\n",
    "            # !pip uninstall -y torch  torchvision torchaudio # Remove existing pytorch install.\n",
    "            # !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # Install pytorch for cuda 11.3\n",
    "            s = subprocess.getoutput('nvidia-smi')\n",
    "            if 'A4000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/raw/main/a4000/xformers-0.0.18%2Bda27862.d20230413-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A5000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A6000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'P5000' in s:\n",
    "                xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/p5000/xformers-0.0.16%2B6f3c20f.d20230127-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 4000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'RTX 5000' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'A100' in s:\n",
    "                xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            elif 'M4000' in s:\n",
    "                print('xformers for M4000 hasn\\'t been built yet.')\n",
    "                # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "            else:\n",
    "                print('GPU not matched to xformers binary so a one-size-fits-all binary was installed. If you have any issues, please build xformers using the Tools block below.')\n",
    "                xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "        if xformers_whl:\n",
    "            !pip uninstall -y xformers\n",
    "            # We're going to install xformers without installing any of its dependencies since they should already be installed.\n",
    "            # If you have any issues then replacing --no-dependencies with --force-reinstall\n",
    "            !pip install --no-dependencies \"{xformers_whl}\"\n",
    "            if delete_whl:\n",
    "                !rm -rf \"{xformers_whl}\"\n",
    "# Make sure important directories exists\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{model_storage_dir}/vae\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/VAE\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/Lora\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/log/images\"\n",
    "\n",
    "!echo -e \"\\n===================================\\nDone! If you're seeing this the process has exited successfully.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0EINk5M0s-w",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Download the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to repeat this step if you've already downloaded the models.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Want a model that isn't listed? [Use the automated model downloader!](#Automated-Model-Downloader)**\n",
    "\n",
    "<br>\n",
    "\n",
    "There are additional models available here: https://cyberes.github.io/stable-diffusion-models\n",
    "\n",
    "Textual inversion: https://cyberes.github.io/stable-diffusion-textual-inversion-models\n",
    "\n",
    "DreamBooth: https://cyberes.github.io/stable-diffusion-dreambooth-library\n",
    "\n",
    "<br>\n",
    "\n",
    "### Filesize and Storage Disclaimer\n",
    "\n",
    "Paperspace free tier has only 5GB of storage space. If you're having storage issues, here are a few suggestions.\n",
    "1. Download everything to `/tmp/` each time you start the machine.\n",
    "2. Add a payment method to your account. Storage overages are billed at \\$0.29/GB and billing occurs monthly and runs at midnight on the first of each month. With a payment method on file, Paperspace will let you use more storage and if you time it right you shouldn't actually be charged for it.\n",
    "3. Upgrade to a Pro account. They'll give you 15GB and you'll get longer runtimes and more powerful free GPUs.\n",
    "4. Use my referral code `KQLRH37`. You'll get \\$10 credit that you should be able to put towards the storage overage charges. Redeem the code at the bottom of the Billing page.\n",
    "\n",
    "### Torrent Instructions\n",
    "\n",
    "Aria2 may show some errors/warnings while downloading. Those are fine, when it eventually says \"Download Complete\" that means everything worked as it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**768x768**\n",
    "\n",
    "This model can generate images 768 pixels by 768 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "!aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue https://huggingface.co/stabilityai/stable-diffusion-2/resolve/main/768-v-ema.ckpt -d \"{model_storage_dir}\" -o \"sd-v2-0-768-v-ema.ckpt\"\n",
    "!wget https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml -O \"{model_storage_dir}/sd-v2-0-768-v-ema.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**512x512 Base**\n",
    "\n",
    "Referred to as the \"base\" model, this model generates images in the standard 512x512 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "!aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue https://huggingface.co/stabilityai/stable-diffusion-2-base/resolve/main/512-base-ema.ckpt -d \"{model_storage_dir}\" -o \"sd-v2-0-512-base-ema.ckpt\"\n",
    "!wget https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference.yaml -O \"{model_storage_dir}/sd-v2-0-512-base-ema.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "!aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue https://huggingface.co/stabilityai/stable-diffusion-2-depth/resolve/main/512-depth-ema.ckpt -d \"{model_storage_dir}\" -o \"sd-v2-0-512-depth-ema.ckpt\"\n",
    "!wget https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-midas-inference.yaml -O \"{model_storage_dir}/sd-v2-0-512-depth-ema.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4x Upscaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "!aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue https://huggingface.co/stabilityai/stable-diffusion-x4-upscaler/resolve/main/x4-upscaler-ema.ckpt -d \"{model_storage_dir}\" -o \"sd-v2-0-x4-upscaler-ema.ckpt\"\n",
    "!wget https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/x4-upscaling.yaml -O \"{model_storage_dir}/sd-v2-0-x4-upscaler-ema.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stable Diffusion 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v1.5**\n",
    "\n",
    "Paperspace includes this model in its public data sources, which don't use up your storage quota. To add it, click on `Data Sources` in the toolbar, `Public`, and `stable-diffusion-classic`. The file is mounted at `/datasets/stable-diffusion-classic/`. You only need to do this once, it will stay mounted between sessions. Make sure the setting `search_paperspace_datasets` is set to `True` so the program will link it to the WebUI.\n",
    "\n",
    "Otherwise, you can download it yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!apt update\n",
    "!apt install -y aria2\n",
    "%cd \"{model_storage_dir}\"\n",
    "!aria2c --seed-time=0 --max-overall-upload-limit=1K --bt-max-peers=120 --summary-interval=0 --file-allocation=none \"magnet:?xt=urn:btih:2daef5b5f63a16a9af9169a529b1a773fc452637&dn=v1-5-pruned-emaonly.ckpt&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2fopen.stealth.si%3a80%2fannounce&tr=udp%3a%2f%2fvibe.sleepyinternetfun.xyz%3a1738%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.zemoj.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.publictracker.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.lelux.fi%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.dler.org%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.army%3a6969%2fannounce\"\n",
    "!mv \"v1-5-pruned-emaonly.ckpt\" \"sd-v1-5-pruned-emaonly.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v1.5 Inpainting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!apt update\n",
    "!apt install -y aria2\n",
    "%cd \"{model_storage_dir}\"\n",
    "!aria2c --seed-time=0 --max-overall-upload-limit=1K --bt-max-peers=120 --summary-interval=0 --file-allocation=none \"magnet:?xt=urn:btih:b523a9e71ae02e27b28007eca190f41999c2add1&dn=sd-v1-5-inpainting.ckpt&tr=udp%3a%2f%2ftracker.opentrackr.org%3a1337%2fannounce&tr=udp%3a%2f%2f9.rarbg.com%3a2810%2fannounce&tr=udp%3a%2f%2ftracker.openbittorrent.com%3a6969%2fannounce&tr=http%3a%2f%2ftracker.openbittorrent.com%3a80%2fannounce&tr=udp%3a%2f%2fopentracker.i2p.rocks%3a6969%2fannounce&tr=https%3a%2f%2fopentracker.i2p.rocks%3a443%2fannounce&tr=udp%3a%2f%2ftracker.torrent.eu.org%3a451%2fannounce&tr=udp%3a%2f%2fopen.stealth.si%3a80%2fannounce&tr=udp%3a%2f%2fvibe.sleepyinternetfun.xyz%3a1738%2fannounce&tr=udp%3a%2f%2ftracker2.dler.org%3a80%2fannounce&tr=udp%3a%2f%2ftracker1.bt.moack.co.kr%3a80%2fannounce&tr=udp%3a%2f%2ftracker.zemoj.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.tiny-vps.com%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.theoks.net%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.swateam.org.uk%3a2710%2fannounce&tr=udp%3a%2f%2ftracker.publictracker.xyz%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.pomf.se%3a80%2fannounce&tr=udp%3a%2f%2ftracker.monitorit4.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.moeking.me%3a6969%2fannounce&tr=udp%3a%2f%2ftracker.lelux.fi%3a6969%2fannounce\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v1.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "!apt update\n",
    "!apt install -y aria2\n",
    "%cd \"{model_storage_dir}\"\n",
    "!aria2c --seed-time=0 --max-overall-upload-limit=1K --bt-max-peers=120 --summary-interval=0 --file-allocation=none \"magnet:?xt=urn:btih:3A4A612D75ED088EA542ACAC52F9F45987488D1C&tr=udp://tracker.opentrackr.org:1337/announce\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean up and restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T14:48:59.393690Z",
     "iopub.status.busy": "2024-12-21T14:48:59.393251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 520\n",
      "Purged pip cache\n",
      "rm: cannot remove '*.aria2': No such file or directory\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Package 'aria2' is not installed, so not removed\n",
      "Package 'p7zip-full' is not installed, so not removed\n",
      "0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir pip_cache_dir\n",
    "    test = [model_storage_dir, repo_storage_dir, pip_cache_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get some storage back\n",
    "if not pip_cache_dir:\n",
    "    !pip cache purge\n",
    "    !echo \"Purged pip cache\"\n",
    "!cd \"{model_storage_dir}\" && rm *.aria2\n",
    "!apt remove --purge -y aria2 p7zip-full\n",
    "!apt autoremove --purge -y\n",
    "!apt clean\n",
    "\n",
    "# Restart the kernel\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link the models directory\n",
    "\n",
    "Create symlinks. The file will be stored in the models storage directory and linked to where the WebUI expects the files to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:34:38.155957Z",
     "iopub.status.busy": "2024-12-22T07:34:38.155616Z",
     "iopub.status.idle": "2024-12-22T07:34:38.238726Z",
     "shell.execute_reply": "2024-12-22T07:34:38.237793Z",
     "shell.execute_reply.started": "2024-12-22T07:34:38.155928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing broken symlinks...\n",
      "\n",
      "Linking .ckpt and .safetensor/.safetensors/.st files in /tmp/stable-diffusion-models\n",
      "\n",
      "Linking config .yaml files in /tmp/stable-diffusion-models\n",
      "\n",
      "Linking hypernetworks...\n",
      "\n",
      "Linking VAEs...\n",
      "\n",
      "Linking Loras...\n",
      "Lora storage directory not found: /tmp/stable-diffusion-models/Lora\n",
      "\n",
      "Linking NovelAI files for each of the NovelAI models...\n",
      "\n",
      "Linking NovelAI anime VAE...\n",
      "\n",
      "Linking .ckpt and .safetensor/.safetensors/.st files in /datasets\n",
      "/datasets/stable-diffusion-classic/SDv1.5.ckpt -> /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/SDv1.5.ckpt\n",
      "\n",
      "Linking config .yaml files in /datasets\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir link_novelai_anime_vae search_paperspace_datasets\n",
    "    test = [model_storage_dir, repo_storage_dir, link_novelai_anime_vae, search_paperspace_datasets]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "model_storage_dir = Path(model_storage_dir)\n",
    "\n",
    "if not model_storage_dir.exists():\n",
    "    print('Your model storage directory does not exist:', model_storage_dir)\n",
    "    sys.exit(1)\n",
    "\n",
    "webui_root_model_path = Path(repo_storage_dir, 'stable-diffusion-webui/models')\n",
    "webui_sd_model_path = Path(webui_root_model_path, 'Stable-diffusion')\n",
    "webui_hypernetwork_path = Path(webui_root_model_path, 'hypernetworks')\n",
    "webui_vae_path = Path(webui_root_model_path, 'VAE')\n",
    "webui_lora_model_path = Path(webui_root_model_path, 'Lora')\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    deleted = False\n",
    "    dir = Path(dir)\n",
    "    for file in dir.iterdir():\n",
    "        if file.is_symlink() and not file.exists():\n",
    "            print('Symlink broken, removing:', file)\n",
    "            file.unlink()\n",
    "            deleted = True\n",
    "    if deleted:\n",
    "        print('')\n",
    "\n",
    "def create_symlink(source, dest):\n",
    "    if os.path.isdir(dest):\n",
    "        dest = Path(dest, os.path.basename(source))\n",
    "    if not dest.exists():\n",
    "        os.symlink(source, dest)\n",
    "    print(source, '->', Path(dest).absolute())\n",
    "\n",
    "# Check for broken symlinks and remove them\n",
    "print('Removing broken symlinks...')\n",
    "delete_broken_symlinks(webui_sd_model_path)\n",
    "delete_broken_symlinks(webui_hypernetwork_path)\n",
    "delete_broken_symlinks(webui_vae_path)\n",
    "delete_broken_symlinks(webui_lora_model_path)\n",
    "\n",
    "def link_ckpts(source_path):\n",
    "    # Link .ckpt and .safetensor/.st files (recursive)\n",
    "    print('\\nLinking .ckpt and .safetensor/.safetensors/.st files in', source_path)\n",
    "    source_path = Path(source_path)\n",
    "    for file in [p for p in source_path.rglob('*') if p.suffix in ['.ckpt', '.safetensor', '.safetensors', '.st']]:\n",
    "        if Path(file).parent.parts[-1] not in ['hypernetworks', 'vae'] :\n",
    "            if not (webui_sd_model_path / file.name):\n",
    "                print('New model:', file.name)\n",
    "            create_symlink(file, webui_sd_model_path)\n",
    "    # Link config yaml files\n",
    "    print('\\nLinking config .yaml files in', source_path)\n",
    "    for file in model_storage_dir.glob('*.yaml'):\n",
    "        create_symlink(file, webui_sd_model_path)\n",
    "\n",
    "\n",
    "link_ckpts(model_storage_dir)\n",
    "\n",
    "# Link hypernetworks\n",
    "print('\\nLinking hypernetworks...')\n",
    "hypernetwork_source_path = Path(model_storage_dir, 'hypernetworks')\n",
    "if hypernetwork_source_path.is_dir():\n",
    "    for file in hypernetwork_source_path.iterdir():\n",
    "        create_symlink(hypernetwork_source_path / file, webui_hypernetwork_path)\n",
    "else:\n",
    "    print('Hypernetwork storage directory not found:', hypernetwork_source_path)\n",
    "\n",
    "# Link VAEs\n",
    "print('\\nLinking VAEs...')\n",
    "vae_source_path = Path(model_storage_dir, 'vae')\n",
    "if vae_source_path.is_dir():\n",
    "    for file in vae_source_path.iterdir():\n",
    "        create_symlink(vae_source_path / file, webui_vae_path)\n",
    "else:\n",
    "    print('VAE storage directory not found:', vae_source_path)\n",
    "\n",
    "# Link Lora\n",
    "print('\\nLinking Loras...')\n",
    "lora_source_path = Path(model_storage_dir, 'Lora')\n",
    "if lora_source_path.is_dir():\n",
    "    for file in lora_source_path.iterdir():\n",
    "        create_symlink(lora_source_path / file, webui_lora_model_path)\n",
    "else:\n",
    "    print('Lora storage directory not found:', lora_source_path)\n",
    "\n",
    "# Link the NovelAI files for each of the NovelAI models\n",
    "print('\\nLinking NovelAI files for each of the NovelAI models...')\n",
    "for model in model_storage_dir.glob('novelai-*.ckpt'):\n",
    "    yaml = model.stem + '.yaml'\n",
    "    if os.path.exists(yaml):\n",
    "        print('New NovelAI model config:', yaml)\n",
    "        create_symlink(yaml, webui_sd_model_path)\n",
    "\n",
    "if link_novelai_anime_vae:\n",
    "    print('\\nLinking NovelAI anime VAE...')\n",
    "    for model in model_storage_dir.glob('novelai-*.ckpt'):\n",
    "        if (model_storage_dir / 'hypernetworks' / 'animevae.pt').is_file():\n",
    "            vae = model.stem + '.vae.pt'\n",
    "            if not os.path.exists(webui_vae_path):\n",
    "                print(f'Linking NovelAI {vae} and {model}')\n",
    "            create_symlink(model_storage_dir / 'hypernetworks' / 'animevae.pt', webui_vae_path)\n",
    "        else:\n",
    "            print(f'{model_storage_dir}/hypernetworks/animevae.pt not found!')\n",
    "\n",
    "if search_paperspace_datasets:\n",
    "    if Path('/datasets').is_dir():\n",
    "        link_ckpts('/datasets')\n",
    "    else:\n",
    "        print('\\nNo datasets mounted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt8lbdmC04ox"
   },
   "source": [
    "# Launch the WebUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Run this block to launch the WebUI. You will get a link to nnn.gradio.app, that's your WebUI. Follow it.\n",
    "\n",
    "See [shared.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/shared.py#L22) to view the code for the launch args. There's a lot of good info in there about exactly what the args do. If you aren't a programmer, [here's the wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings).\n",
    "\n",
    "#### Troubleshooting\n",
    "- If you have any issues, try restarting the kernel.\n",
    "- `EOFError: Ran out of input` probably means you ran out of storage space and the model `.ckpt` file wasn't downloaded completely. Try cleaning up your files. There are some helpful scripts in the Tools section below.\n",
    "- `The file may be malicious, so the program is not going to read it` means the program encountered unexpected data in the model file (the technical term is \"pickle\"). Merging models can cause this. You can disable this feature by setting `disable_pickle_check` to True in the settings block.\n",
    "- Try updating your notebook using the block in the Tools section below.\n",
    "- If you're still having issues, delete `stable-diffusion-webui` and reinstall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:34:42.095751Z",
     "iopub.status.busy": "2024-12-22T07:34:42.095396Z",
     "iopub.status.idle": "2024-12-22T07:35:27.196119Z",
     "shell.execute_reply": "2024-12-22T07:35:27.195351Z",
     "shell.execute_reply.started": "2024-12-22T07:34:42.095721Z"
    },
    "id": "R-xAdMA5wxXd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/stable-diffusion/stable-diffusion-webui\n",
      "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.5.1+cu121 with CUDA 1201 (you have 2.1.2+cu121)\n",
      "    Python  3.10.15 (you have 3.10.10)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
      "no module 'xformers'. Processing without...\n",
      "no module 'xformers'. Processing without...\n",
      "No module 'xformers'. Proceeding without it.\n",
      "*** Cannot import xformers\n",
      "    Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.10/dist-packages/xformers/checkpoint.py\", line 53, in <module>\n",
      "        from torch.utils.checkpoint import SAC_IGNORED_OPS as _ignored_ops  # type: ignore\n",
      "    ImportError: cannot import name 'SAC_IGNORED_OPS' from 'torch.utils.checkpoint' (/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py)\n",
      "\n",
      "    During handling of the above exception, another exception occurred:\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "      File \"/storage/stable-diffusion/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 160, in <module>\n",
      "        import xformers.ops\n",
      "      File \"/usr/local/lib/python3.10/dist-packages/xformers/__init__.py\", line 12, in <module>\n",
      "        from .checkpoint import (  # noqa: E402, F401\n",
      "      File \"/usr/local/lib/python3.10/dist-packages/xformers/checkpoint.py\", line 57, in <module>\n",
      "        from torch.utils.checkpoint import _ignored_ops  # type: ignore\n",
      "    ImportError: cannot import name '_ignored_ops' from 'torch.utils.checkpoint' (/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py)\n",
      "\n",
      "---\n",
      "Loading weights [4c86efd062] from /storage/stable-diffusion/stable-diffusion-webui/models/Stable-diffusion/SDv1.5.ckpt\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://67d0225a927c171c9d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
      "Startup time: 18.7s (import torch: 6.0s, import gradio: 1.6s, setup paths: 4.9s, initialize shared: 0.7s, other imports: 1.3s, list SD models: 0.2s, load scripts: 1.6s, initialize extra networks: 0.1s, create ui: 1.1s, gradio launch: 1.1s).\n",
      "^C\n",
      "Interrupted with signal 2 in <frame at 0x103caf20, file '/usr/lib/python3.10/threading.py', line 324, code wait>\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth ui_theme insecure_extension_access gradio_queue\n",
    "    test = [model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, activate_medvram, disable_pickle_check, gradio_port, gradio_auth, ui_theme, insecure_extension_access, gradio_queue]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "\n",
    "# Code to set the options you want as defined in the very first block\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else ''\n",
    "theme = f'--theme {ui_theme}' if ui_theme else ''\n",
    "insecure_extension_access = '--enable-insecure-extension-access' if insecure_extension_access else ''\n",
    "queue = '--gradio-queue' if gradio_queue else ''\n",
    "\n",
    "# Launch args go below:\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} {theme} {queue}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Export Generations\n",
    "\n",
    "This block will rename and compress the outputs with 7zip max compression. It expects you to have `log/` and `outputs/` in `/notebooks/stable-diffusion-webui/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir export_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir, export_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "export_storage_dir = Path(export_storage_dir)\n",
    "export_storage_dir.mkdir(exist_ok=True)\n",
    "\n",
    "!if [ $(dpkg-query -W -f='${Status}' p7zip-full 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y p7zip-full; fi # install 7z if it isn't already installed\n",
    "from datetime import datetime\n",
    "datetime_str = datetime.now().strftime('%m-%d-%Y_%H-%M-%S')\n",
    "%cd \"{export_storage_dir}\"\n",
    "!mkdir -p \"{datetime_str}/log\"\n",
    "!cd \"{repo_storage_dir / 'stable-diffusion-webui' / 'log'}\" && mv * \"{export_storage_dir / datetime_str / 'log'}\"\n",
    "!cd \"{repo_storage_dir / 'stable-diffusion-webui' / 'outputs'}\" && mv * \"{export_storage_dir / datetime_str}\"\n",
    "s = subprocess.run(f'find \"{Path(export_storage_dir, datetime_str)}\" -type d -name .ipynb_checkpoints -exec rm -rv {{}} +', shell=True)\n",
    "print('Compressing folder:', export_storage_dir / datetime_str)\n",
    "!7z a -t7z -m0=lzma2 -mx=9 -mfb=64 -md=32m -ms=on \"{datetime_str}.7z\" \"{export_storage_dir / datetime_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delete old output folder\n",
    "\n",
    "This block will delete the folder you just compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf \"{export_storage_dir / datetime_str}\"\n",
    "# !echo \"Deleted {export_storage_dir / datetime_str}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Update this notebook from Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this and refresh the page (press F5). Don't save anything or you will overwrite the downloaded file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb.backup # save your old notebook to a backup\n",
    "!wget https://raw.githubusercontent.com/Engineer-of-Stuff/stable-diffusion-paperspace/main/StableDiffusionUI_Voldemort_paperspace.ipynb -O /notebooks/StableDiffusionUI_Voldemort_paperspace.ipynb\n",
    "!echo \"Downloaded! Now, refresh the page (press F5). Don't save anything or you will overwrite the downloaded file.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Automated Model Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a tool to download a model from a torrent magnet link, web link, Google Drive, HuggingFace, or CivitAI.\n",
    "\n",
    "Websites may update and this download could go out of date. If you encounter any problems, please [open an issue](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/issues/new) on this notebook's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-21T15:10:38.993034Z",
     "iopub.status.busy": "2024-12-21T15:10:38.992336Z",
     "iopub.status.idle": "2024-12-21T15:10:44.073312Z",
     "shell.execute_reply": "2024-12-21T15:10:44.071758Z",
     "shell.execute_reply.started": "2024-12-21T15:10:38.992964Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URI of model to download:  https://civitai.com/models/224372/inna-nobody\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'modelVersions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(soup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscript\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__NEXT_DATA__\u001b[39m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     75\u001b[0m model_data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprops\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpageProps\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrpcState\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 76\u001b[0m latest_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodelVersions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     77\u001b[0m latest_model_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://civitai.com/api/download/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatest_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading model:\u001b[39m\u001b[38;5;124m'\u001b[39m, model_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'modelVersions'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "model_uri = input('URI of model to download: ')\n",
    "import re\n",
    "import requests\n",
    "import gdown\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
    "\n",
    "def is_url(url_str):\n",
    "    return re.search(r'https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}', url_str)\n",
    "\n",
    "def dl_web_file(web_dl_file, filename=None):\n",
    "    web_dl_file = is_url(web_dl_file)[0] # clean the URL string\n",
    "    !if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "    if filename:\n",
    "        filename_cmd = f'--out=\"{filename}\"'\n",
    "    else:\n",
    "        filename_cmd = ''\n",
    "    # We're going to use aria2 to split the download into threads which will allow us to download\n",
    "    # the file very fast even if the site serves the file slow.\n",
    "    !cd \"{model_storage_dir}\" && aria2c --file-allocation=none -c -x 16 -s 16 --summary-interval=0 --console-log-level=warn --continue --user-agent \"{user_agent}\" {filename_cmd} \"{web_dl_file}\" \n",
    "\n",
    "magnet_match = re.search(r'magnet:\\?xt=urn:btih:[\\-_A-Za-z0-9&=%.]*', model_uri)\n",
    "civitai_match = re.search(r'^https?:\\/\\/(?:www\\.|(?!www))civitai\\.com\\/models\\/\\d*\\/.*?$', model_uri)\n",
    "web_match = is_url(model_uri)\n",
    "\n",
    "if magnet_match:\n",
    "    !if [ $(dpkg-query -W -f='${Status}' aria2 2>/dev/null | grep -c \"ok installed\") = 0 ]; then sudo apt update && sudo apt install -y aria2; fi\n",
    "    %cd \"{model_storage_dir}\"\n",
    "    bash_var = magnet_match[0]\n",
    "    !aria2c --seed-time=0 --max-overall-upload-limit=1K --bt-max-peers=120 --summary-interval=0 --console-log-level=warn --file-allocation=none \"{bash_var}\"\n",
    "    # clean exit here\n",
    "elif 'https://huggingface.co/' in model_uri:\n",
    "    from urllib.parse import urlparse\n",
    "    filename = os.path.basename(urlparse(model_uri.replace('/blob/', '/resolve/')).path)\n",
    "    response = requests.head(model_uri, allow_redirects=True, headers={'User-Agent': user_agent})\n",
    "    if 'octet-stream' not in response.headers['content-type']:\n",
    "        response = requests.head(model_uri.replace('/blob/', '/resolve/'), allow_redirects=True, headers={'User-Agent': user_agent})\n",
    "        if 'octet-stream' not in response.headers['content-type']:\n",
    "            print(f'Wrong content-type: {response.headers[\"content-type\"].split(\";\")[0]}')\n",
    "            # clean exit here\n",
    "        else:\n",
    "            dl_web_file(model_uri.replace('/blob/', '/resolve/'), filename)\n",
    "            # clean exit here\n",
    "    else:\n",
    "        dl_web_file(model_uri, filename)\n",
    "        # clean exit here\n",
    "elif 'https://drive.google.com' in model_uri:\n",
    "    gdrive_file_id, _ = gdown.parse_url.parse_url(model_uri)\n",
    "    %cd \"{model_storage_dir}\"\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={gdrive_file_id}&confirm=t\")\n",
    "    # clean exit here\n",
    "elif civitai_match:\n",
    "    if not is_url(civitai_match[0]):\n",
    "        print('URL does not match known civitai.com pattern.')\n",
    "        # clean exit here\n",
    "    else:\n",
    "        soup = BeautifulSoup(requests.get(model_uri, headers={'User-Agent': user_agent}).text, features=\"html.parser\")\n",
    "        data = json.loads(soup.find('script', {'id': '__NEXT_DATA__'}).text)\n",
    "        model_data = data[\"props\"][\"pageProps\"][\"trpcState\"][\"json\"][\"queries\"][0][\"state\"][\"data\"]\n",
    "        latest_model = model_data['modelVersions'][0]\n",
    "        latest_model_url = f\"https://civitai.com/api/download/models/{latest_model['id']}\"\n",
    "        print('Downloading model:', model_data['name'])\n",
    "        \n",
    "        # Download the description to a markdown file next to the checkpoint\n",
    "        desc = markdownify(model_data['description'])\n",
    "        req = urllib.request.Request(latest_model_url, data=None, headers={'User-Agent': user_agent})\n",
    "        content_disp = urllib.request.urlopen(req).getheader('Content-Disposition')\n",
    "        if content_disp:\n",
    "            filename = Path(re.match(r'attachment; filename=\"(.*?)\"', content_disp)[1]).stem\n",
    "            with open(Path(model_storage_dir, f'{filename}.md'), 'w') as file:\n",
    "                file.write(f\"# {model_data['name']}\\n\")\n",
    "                file.write(f'Original CivitAI URL: {model_uri}\\n\\n<br>\\n\\n')\n",
    "                file.write(desc)\n",
    "        else:\n",
    "            print('Failed to get filename of checkpoint for markdown file')\n",
    "        dl_web_file(latest_model_url)\n",
    "        # clean exit here\n",
    "elif web_match:\n",
    "    # Always do the web match last\n",
    "    with requests.get(web_match[0], allow_redirects=True, stream=True, headers={'User-Agent': user_agent}) as r:\n",
    "        # Uing GET since some servers respond differently to HEAD.\n",
    "        # Using `with` so we can close the connection and not download the entire file.\n",
    "        response = r\n",
    "        r.close()\n",
    "    if response.headers.get('content-type') or response.headers.get('content-disposition'):\n",
    "        if 'octet-stream' in response.headers.get('content-type', '') or 'attachment' in response.headers.get('content-disposition', ''):\n",
    "            dl_web_file(model_uri)\n",
    "            # clean exit here\n",
    "        else:\n",
    "            print('Required HTTP headers are incorrect. One of these needs to be correct:', end='\\n\\n')\n",
    "            print('Content-Type:', response.headers['content-type'].split(\";\")[0] if response.headers.get('content-type') else 'None')\n",
    "            print('Must be \"application/octet-stream\"', end='\\n\\n')\n",
    "            print('Content-Disposition:', response.headers['content-disposition'] if response.headers.get('content-disposition') else 'None')\n",
    "            print('Must start with \"attachment;\"')\n",
    "            # clean exit here\n",
    "    else:\n",
    "        print('Required HTTP headers are missing. You need at lease one of these:', end='\\n\\n')\n",
    "        print('Content-Type:', response.headers['content-type'].split(\";\")[0] if response.headers.get('content-type') else 'None')\n",
    "        print('Must be \"application/octet-stream\"', end='\\n\\n')\n",
    "        print('Content-Disposition:', response.headers['content-disposition'] if response.headers.get('content-disposition') else 'None')\n",
    "        print('Must start with \"attachment;\"')\n",
    "else:\n",
    "    print('Could not parse your URI.')\n",
    "    # clean exit here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download model from Civit AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T17:54:12.162598Z",
     "iopub.status.busy": "2024-12-21T17:54:12.161669Z",
     "iopub.status.idle": "2024-12-21T17:54:19.910707Z",
     "shell.execute_reply": "2024-12-21T17:54:19.909623Z",
     "shell.execute_reply.started": "2024-12-21T17:54:12.162568Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your CiviAI Token: ce7f051c7d8a244671e1737f840dfb6f\n",
      "Model download URL: https://civitai.com/api/download/models/253081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: InnaNobodySD15.pt [100.00%] - 24.31 MB/s\n",
      "Download completed. File saved as: InnaNobodySD15.pt\n",
      "Downloaded in 0s\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir\n",
    "    test = [model_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from pathlib import Path\n",
    "\n",
    "def download_file(url: str, output_path: str, token: str):\n",
    "    CHUNK_SIZE = 1638400\n",
    "    USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}',\n",
    "        'User-Agent': USER_AGENT,\n",
    "    }\n",
    "\n",
    "    # Disable automatic redirect handling\n",
    "    class NoRedirection(urllib.request.HTTPErrorProcessor):\n",
    "        def http_response(self, request, response):\n",
    "            return response\n",
    "        https_response = http_response\n",
    "\n",
    "    request = urllib.request.Request(url, headers=headers)\n",
    "    opener = urllib.request.build_opener(NoRedirection)\n",
    "    response = opener.open(request)\n",
    "\n",
    "    if response.status in [301, 302, 303, 307, 308]:\n",
    "        redirect_url = response.getheader('Location')\n",
    "\n",
    "        # Extract filename from the redirect URL\n",
    "        parsed_url = urlparse(redirect_url)\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        content_disposition = query_params.get('response-content-disposition', [None])[0]\n",
    "\n",
    "        if content_disposition:\n",
    "            filename = unquote(content_disposition.split('filename=')[1].strip('\"'))\n",
    "        else:\n",
    "            raise Exception('Unable to determine filename')\n",
    "\n",
    "        response = urllib.request.urlopen(redirect_url)\n",
    "    elif response.status == 404:\n",
    "        raise Exception('File not found')\n",
    "    else:\n",
    "        raise Exception('No redirect found, something went wrong')\n",
    "\n",
    "    total_size = response.getheader('Content-Length')\n",
    "\n",
    "    if total_size is not None:\n",
    "        total_size = int(total_size)\n",
    "\n",
    "    output = Path(output_path)\n",
    "    output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(Path(output_path)/filename, 'wb') as f:\n",
    "        downloaded = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            chunk_start_time = time.time()\n",
    "            buffer = response.read(CHUNK_SIZE)\n",
    "            chunk_end_time = time.time()\n",
    "\n",
    "            if not buffer:\n",
    "                break\n",
    "\n",
    "            downloaded += len(buffer)\n",
    "            f.write(buffer)\n",
    "            chunk_time = chunk_end_time - chunk_start_time\n",
    "\n",
    "            if chunk_time > 0:\n",
    "                speed = len(buffer) / chunk_time / (1024 ** 2)  # Speed in MB/s\n",
    "\n",
    "            if total_size is not None:\n",
    "                progress = downloaded / total_size\n",
    "                sys.stdout.write(f'\\rDownloading: {filename} [{progress*100:.2f}%] - {speed:.2f} MB/s')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    hours, remainder = divmod(time_taken, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        time_str = f'{int(hours)}h {int(minutes)}m {int(seconds)}s'\n",
    "    elif minutes > 0:\n",
    "        time_str = f'{int(minutes)}m {int(seconds)}s'\n",
    "    else:\n",
    "        time_str = f'{int(seconds)}s'\n",
    "\n",
    "    sys.stdout.write('\\n')\n",
    "    print(f'Download completed. File saved as: {filename}')\n",
    "    print(f'Downloaded in {time_str}')\n",
    "\n",
    "token = input(\"Your CiviAI Token:\")\n",
    "url = \"https://civitai.com/api/download/models/253081\"\n",
    "download_file(url, model_storage_dir, token)\n",
    "\n",
    "# Inna Nobody\n",
    "# https://civitai.com/api/download/models/253081"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Custom Scripts Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom scripts is an easy way to add simple functionality to the WebUI. The custom script system has been replaced by extensions that provide similar functionality but some people still rely on these scripts. This block will install some of the most popular scripts. Just note that some of these scripts may be outdated and possibly not work.\n",
    "\n",
    "https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import shutil\n",
    "import requests\n",
    "from pathlib import Path\n",
    "!pip install moviepy==1.0.3\n",
    "!apt update\n",
    "!apt install -y potrace python3-tk\n",
    "\n",
    "def update_repo_if_not_exists(path, repo_clone_url):\n",
    "    if not os.path.exists(path):\n",
    "        !git clone \"{repo_clone_url}\" \"{path}\"\n",
    "    else:\n",
    "        print(f'{repo_clone_url.split(\"/\")[-1]} already downloaded, updating...')\n",
    "        !cd \"{path}\" && git pull # no % so we don't interfere with the main process\n",
    "\n",
    "def download_file_dir(url, output_dir):\n",
    "    # output_dir must have a trailing slash\n",
    "    local_filename = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(f'{output_dir}{local_filename}', 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "    return local_filename\n",
    "def do_script_download(scripts_list, domain, path):\n",
    "    for item in scripts_list:\n",
    "        download_file_dir(f'https://{domain}/{item}', path)\n",
    "        print(f'{item.split(\"/\")[-1]} downloaded...')\n",
    "\n",
    "repo_storage_dir = Path(repo_storage_dir)\n",
    "webui_dir = repo_storage_dir / 'stable-diffusion-webui'\n",
    "scripts_dir = webui_dir / 'scripts'\n",
    "        \n",
    "do_script_download([\n",
    "    'GRMrGecko/stable-diffusion-webui-automatic/advanced_matrix/scripts/advanced_prompt_matrix.py',\n",
    "    'dfaker/stable-diffusion-webui-cv2-external-masking-script/main/external_masking.py',\n",
    "    'memes-forever/Stable-diffusion-webui-video/main/videos.py',\n",
    "    'yownas/seed_travel/main/scripts/seed_travel.py',\n",
    "    'Animator-Anon/Animator/main/animation.py',\n",
    "    'Filarius/stable-diffusion-webui/master/scripts/vid2vid.py',\n",
    "    'GeorgLegato/Txt2Vectorgraphics/main/txt2vectorgfx.py',\n",
    "    'yownas/shift-attention/main/scripts/shift_attention.py',\n",
    "    'DiceOwl/StableDiffusionStuff/main/loopback_superimpose.py',\n",
    "    'Engineer-of-Stuff/stable-diffusion-paperspace/main/other/save_steps.py',\n",
    "    'Pfaeff/sd-web-ui-scripts/main/moisaic.py'\n",
    "], 'raw.githubusercontent.com', scripts_dir)\n",
    "\n",
    "do_script_download([\n",
    "    'dfaker/f88aa62e3a14b559fe4e5f6b345db664/raw/791dabfa0ab26399aa2635bcbc1cf6267aa4ffc2/alternate_sampler_noise_schedules.py',\n",
    "    'camenduru/9ec5f8141db9902e375967e93250860f/raw/c1a03eb447548adbef1858c0e69d3567a390d2f4/run_n_times.py'\n",
    "], 'gist.githubusercontent.com', scripts_dir)\n",
    "\n",
    "# Download and set up txt2img2img\n",
    "update_repo_if_not_exists(webui_dir / 'txt2img2img_root', 'https://github.com/ThereforeGames/txt2img2img.git')\n",
    "!cp -r \"{webui_dir}/txt2img2img_root/scripts\" \"{webui_dir}\"\n",
    "!cp -r \"{webui_dir}/txt2img2img_root/txt2img2img\" \"{webui_dir}\"\n",
    "!cp -r \"{webui_dir}/txt2img2img_root/venv\" \"{webui_dir}\"\n",
    "\n",
    "# Download and set up txt2mask\n",
    "update_repo_if_not_exists(webui_dir / 'txt2mask', 'https://github.com/ThereforeGames/txt2mask.git')\n",
    "!echo \"Copying txt2mask...\"\n",
    "!cp -r \"{webui_dir}/txt2mask/repositories/clipseg\" \"{webui_dir}/repositories\"\n",
    "!cp -r \"{webui_dir}/txt2mask/scripts/\" \"{webui_dir}/\"\n",
    "echo \"Done!\n",
    "# Install the dynamic-prompts/wildcard script\n",
    "# !git clone https://github.com/adieyal/sd-dynamic-prompting/ extensions/dynamic-prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Show graphics card info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:55:51.767462Z",
     "iopub.status.busy": "2024-12-22T07:55:51.767105Z",
     "iopub.status.idle": "2024-12-22T07:55:52.209060Z",
     "shell.execute_reply": "2024-12-22T07:55:52.208055Z",
     "shell.execute_reply.started": "2024-12-22T07:55:51.767435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Quadro P5000 (UUID: GPU-872ab3a9-d10c-463e-1a66-4b3b26ba74b9)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Build and Install Xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After running either of these two blocks you need to re-run the installer block above because you've installed a new Python version.**\n",
    "\n",
    "First, try installing Xformers through pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-22T07:18:53.530718Z",
     "iopub.status.busy": "2024-12-22T07:18:53.530344Z",
     "iopub.status.idle": "2024-12-22T07:21:13.361243Z",
     "shell.execute_reply": "2024-12-22T07:21:13.360647Z",
     "shell.execute_reply.started": "2024-12-22T07:18:53.530718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xformers\n",
      "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.5.1\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.4)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2023.3.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.9.0)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.2)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.1.0\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (2.1.2)\n",
      "Installing collected packages: mpmath, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1+cu116\n",
      "    Uninstalling torch-1.12.1+cu116:\n",
      "      Successfully uninstalled torch-1.12.1+cu116\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1+cu116 requires torch==1.12.1, but you have torch 2.5.1 which is incompatible.\n",
      "torchaudio 0.12.1+cu116 requires torch==1.12.1, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0 typing-extensions-4.12.2 xformers-0.0.28.post3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're still encountering issues then try building it yourself using the next block. You can also try [my old script](https://github.com/Engineer-of-Stuff/stable-diffusion-paperspace/blob/master/other/build-xformers.sh).\n",
    "\n",
    "This will take over 25 minutes but you should only have to do this once. Leave the Xformers `.whl` in `/notebooks/` and it will automatically be installed by the notebook's installer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-21T18:09:22.227748Z",
     "iopub.status.busy": "2024-12-21T18:09:22.227378Z",
     "iopub.status.idle": "2024-12-21T18:11:29.229587Z",
     "shell.execute_reply": "2024-12-21T18:11:29.228216Z",
     "shell.execute_reply.started": "2024-12-21T18:09:22.227717Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:2 https://deb.nodesource.com/node_16.x focal InRelease\n",
      "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "189 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "jq is already the newest version (1.6-1ubuntu0.20.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 189 not upgraded.\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "Cloning into 'xformers'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building version: v0.0.28.post3\n",
      "Collecting xformers\n",
      "  Cloning https://github.com/facebookresearch/xformers.git (to revision v0.0.28.post3) to /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/xformers.git /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434\n",
      "  Running command git checkout -q f3bc7a78e687f7987a920e7bad0dca61c927c5b4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Resolved https://github.com/facebookresearch/xformers.git to commit f3bc7a78e687f7987a920e7bad0dca61c927c5b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git submodule update --init --recursive -q\n",
      "  From https://github.com/NVIDIA/cutlass\n",
      "   * branch              756c351b4994854b2f8c6dded3821ebbb580876b -> FETCH_HEAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: xformers\n",
      "  Building wheel for xformers (setup.py): started\n",
      "  Building wheel for xformers (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [480 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build/lib.linux-x86_64-cpython-310\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/checkpoint.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/info.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/_cpp_lib.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/_deprecation_warning.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/utils.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/test.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      copying xformers/attn_bias_utils.py -> build/lib.linux-x86_64-cpython-310/xformers\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/fused_softmax.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      copying xformers/_flash_attn/bert_padding.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/helpers\n",
      "      copying xformers/helpers/hierarchical_configs.py -> build/lib.linux-x86_64-cpython-310/xformers/helpers\n",
      "      copying xformers/helpers/test_utils.py -> build/lib.linux-x86_64-cpython-310/xformers/helpers\n",
      "      copying xformers/helpers/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/helpers\n",
      "      copying xformers/helpers/timm_sparse_attention.py -> build/lib.linux-x86_64-cpython-310/xformers/helpers\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/sparse\n",
      "      copying xformers/sparse/csr_tensor.py -> build/lib.linux-x86_64-cpython-310/xformers/sparse\n",
      "      copying xformers/sparse/blocksparse_tensor.py -> build/lib.linux-x86_64-cpython-310/xformers/sparse\n",
      "      copying xformers/sparse/_csr_ops.py -> build/lib.linux-x86_64-cpython-310/xformers/sparse\n",
      "      copying xformers/sparse/utils.py -> build/lib.linux-x86_64-cpython-310/xformers/sparse\n",
      "      copying xformers/sparse/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/sparse\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/triton\n",
      "      copying xformers/triton/vararg_kernel.py -> build/lib.linux-x86_64-cpython-310/xformers/triton\n",
      "      copying xformers/triton/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/triton\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/profiler.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/profiler_dcgm.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/find_slowest.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/profile_analyzer.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/api.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      copying xformers/profiler/device_limits.py -> build/lib.linux-x86_64-cpython-310/xformers/profiler\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_multi_head_dispatch.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_revnet.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_indexing.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_sp24.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/utils.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      copying xformers/benchmarks/benchmark_core.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      copying xformers/factory/block_factory.py -> build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      copying xformers/factory/model_factory.py -> build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      copying xformers/factory/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      copying xformers/factory/weight_init.py -> build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      copying xformers/factory/block_configs.py -> build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      copying xformers/factory/hydra_helper.py -> build/lib.linux-x86_64-cpython-310/xformers/factory\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/ipc.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/modpar_layers.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/rope_padded.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/unbind.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/swiglu_op.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/indexing.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/differentiable_collectives.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/seqpar.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/common.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/sp24.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/tiled_matmul.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      copying xformers/ops/rmsnorm.py -> build/lib.linux-x86_64-cpython-310/xformers/ops\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/input_projection.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/residual.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/simplicial_embedding.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/activations.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/reversible.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/multi_head_dispatch.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      copying xformers/components/patch_embedding.py -> build/lib.linux-x86_64-cpython-310/xformers/components\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/layers\n",
      "      copying xformers/_flash_attn/layers/rotary.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/layers\n",
      "      copying xformers/_flash_attn/layers/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/layers\n",
      "      copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/layers\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/losses\n",
      "      copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/losses\n",
      "      copying xformers/_flash_attn/losses/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/losses\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/falcon.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/opt.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/gptj.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/llama.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/baichuan.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/bigcode.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/vit.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/bert.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/btlm.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      copying xformers/_flash_attn/models/gpt.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/models\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/modules\n",
      "      copying xformers/_flash_attn/modules/block.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/modules\n",
      "      copying xformers/_flash_attn/modules/embedding.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/modules\n",
      "      copying xformers/_flash_attn/modules/mlp.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/modules\n",
      "      copying xformers/_flash_attn/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/modules\n",
      "      copying xformers/_flash_attn/modules/mha.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/modules\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/utils\n",
      "      copying xformers/_flash_attn/utils/generation.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/utils\n",
      "      copying xformers/_flash_attn/utils/pretrained.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/utils\n",
      "      copying xformers/_flash_attn/utils/distributed.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/utils\n",
      "      copying xformers/_flash_attn/utils/benchmark.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/utils\n",
      "      copying xformers/_flash_attn/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/utils\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops\n",
      "      copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops\n",
      "      copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops\n",
      "      copying xformers/_flash_attn/ops/activations.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops\n",
      "      copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops\n",
      "      copying xformers/_flash_attn/ops/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/_flash_attn/ops/triton\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      copying xformers/benchmarks/LRA/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA/code\n",
      "      copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA/code\n",
      "      copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA/code\n",
      "      copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/benchmarks/LRA/code\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/ck.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/flash.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/dispatch.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/common.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/ck_splitk.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/attn_bias.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/flash3.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/triton_splitk.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/cutlass.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      copying xformers/ops/fmha/ck_decoder.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      copying xformers/ops/_triton/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/_triton\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/ops/fmha/_triton\n",
      "      copying xformers/ops/fmha/_triton/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha/_triton\n",
      "      copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.linux-x86_64-cpython-310/xformers/ops/fmha/_triton\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/_sputnik_sparse.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/lambda_layer.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/visual.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/sparsity_config.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/nystrom.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/scaled_dot_product.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/core.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/fourier_mix.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/random.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/attention_patterns.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/ortho.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/attention_mask.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/local.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/pooling.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/utils.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/compositional.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/linformer.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/base.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/global_tokens.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      copying xformers/components/attention/favor.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      copying xformers/components/positional_embedding/param.py -> build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      copying xformers/components/positional_embedding/vocab.py -> build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      copying xformers/components/positional_embedding/rotary.py -> build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      copying xformers/components/positional_embedding/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      copying xformers/components/positional_embedding/base.py -> build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      copying xformers/components/positional_embedding/sine.py -> build/lib.linux-x86_64-cpython-310/xformers/components/positional_embedding\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/components/feedforward\n",
      "      copying xformers/components/feedforward/conv_mlp.py -> build/lib.linux-x86_64-cpython-310/xformers/components/feedforward\n",
      "      copying xformers/components/feedforward/mixture_of_experts.py -> build/lib.linux-x86_64-cpython-310/xformers/components/feedforward\n",
      "      copying xformers/components/feedforward/mlp.py -> build/lib.linux-x86_64-cpython-310/xformers/components/feedforward\n",
      "      copying xformers/components/feedforward/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/components/feedforward\n",
      "      copying xformers/components/feedforward/base.py -> build/lib.linux-x86_64-cpython-310/xformers/components/feedforward\n",
      "      creating build/lib.linux-x86_64-cpython-310/xformers/components/attention/feature_maps\n",
      "      copying xformers/components/attention/feature_maps/__init__.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention/feature_maps\n",
      "      copying xformers/components/attention/feature_maps/base.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention/feature_maps\n",
      "      copying xformers/components/attention/feature_maps/softmax.py -> build/lib.linux-x86_64-cpython-310/xformers/components/attention/feature_maps\n",
      "      running build_ext\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:388: UserWarning: The detected CUDA version (11.6) has a minor version mismatch with the version that was used to compile PyTorch (11.8). Most likely this shouldn't be a problem.\n",
      "        warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "      building 'xformers._C' extension\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/autograd\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha/autogen\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha/autogen/impl\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/sequence_parallel_fused\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/sparse24\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/swiglu\n",
      "      creating /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/swiglu/cuda\n",
      "      Emitting ninja build file /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/build.ninja...\n",
      "      Compiling objects...\n",
      "      Using envvar MAX_JOBS (8) as the number of workers...\n",
      "      [1/83] /usr/local/cuda-11.6/bin/nvcc  -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha/attention_backward_generic.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --use_fast_math -DXFORMERS_MEM_EFF_ATTENTION_DISABLE_BACKWARD --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61\n",
      "      FAILED: /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha/attention_backward_generic.o\n",
      "      /usr/local/cuda-11.6/bin/nvcc  -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha/attention_backward_generic.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --use_fast_math -DXFORMERS_MEM_EFF_ATTENTION_DISABLE_BACKWARD --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61\n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(67): error: operand types are incompatible (\"const c10::nullopt_t\" and \"const std::optional<at::Tensor>\")\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(71): error: operand types are incompatible (\"const c10::nullopt_t\" and \"const std::optional<at::Tensor>\")\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(75): error: operand types are incompatible (\"const c10::nullopt_t\" and \"const std::optional<at::Tensor>\")\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(445): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(483): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(483): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(483): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(485): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(485): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(485): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(488): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(488): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(488): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(467): warning #550-D: variable \"callback\" was set but never used\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(543): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(543): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(543): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(545): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(545): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(545): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(548): error: identifier \"dispatch_cutlassB\" is undefined\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(548): error: type name is not allowed\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(548): warning #174-D: expression has no effect\n",
      "      \n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(510): warning #550-D: variable \"callback\" was set but never used\n",
      "      \n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
      "                detected during:\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
      "      (61): here\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
      "      \n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
      "                detected during:\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
      "      (61): here\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
      "      \n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h(1785): error: class \"std::optional<at::Tensor>\" has no member \"element_type\"\n",
      "                detected during:\n",
      "                  instantiation of \"T c10::generic_to(c10::IValue, c10::_fake_type<T>) [with T=std::optional<at::Tensor>]\"\n",
      "      (1917): here\n",
      "                  instantiation of \"T c10::IValue::to<T>() && [with T=std::optional<at::Tensor>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(499): here\n",
      "                  instantiation of \"std::decay_t<c10::guts::infer_function_traits<Functor>::type::return_type> c10::impl::call_functor_with_args_from_stack_<Functor,AllowDeprecatedTypes,ivalue_arg_indices...,ArgTypes...>(c10::OperatorKernel *, c10::DispatchKeySet, c10::Stack *, std::index_sequence<ivalue_arg_indices...>, c10::guts::typelist::typelist<ArgTypes...> *) [with Functor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false, ivalue_arg_indices=<0UL, 1UL, 2UL, 3UL, 4UL, 5UL, 6UL, 7UL, 8UL, 9UL, 10UL, 11UL, 12UL, 13UL, 14UL, 15UL, 16UL, 17UL, 18UL>, ArgTypes=<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(513): here\n",
      "                  instantiation of \"std::decay_t<c10::guts::infer_function_traits<Functor>::type::return_type> c10::impl::call_functor_with_args_from_stack<Functor,AllowDeprecatedTypes>(c10::OperatorKernel *, c10::DispatchKeySet, c10::Stack *) [with Functor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(584): here\n",
      "                  instantiation of \"void c10::impl::make_boxed_from_unboxed_functor<KernelFunctor, AllowDeprecatedTypes>::call(c10::OperatorKernel *, const c10::OperatorHandle &, c10::DispatchKeySet, c10::Stack *) [with KernelFunctor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/KernelFunction_impl.h(159): here\n",
      "                  instantiation of \"c10::KernelFunction c10::KernelFunction::makeFromUnboxedFunctor<AllowLegacyTypes,KernelFunctor>(std::unique_ptr<c10::OperatorKernel, std::default_delete<c10::OperatorKernel>>) [with AllowLegacyTypes=false, KernelFunctor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/KernelFunction_impl.h(181): here\n",
      "                  instantiation of \"c10::KernelFunction c10::KernelFunction::makeFromUnboxedFunction(FuncPtr) [with FuncPtr=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, AllowLegacyTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(131): here\n",
      "                  instantiation of \"torch::CppFunction::CppFunction(FuncPtr, std::enable_if_t<c10::is_compile_time_function_pointer<FuncPtr>::value, std::nullptr_t>) [with FuncPtr=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(659): here\n",
      "                  instantiation of \"torch::Library &torch::Library::impl(Name, Func &&, torch::_RegisterOrVerify) & [with Name=const char *, Func=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(742): here\n",
      "                  instantiation of \"torch::Library &torch::Library::impl(torch::detail::SelectiveStr<true>, Func &&) & [with Func=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(556): here\n",
      "      \n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h(1785): error: class \"std::optional<double>\" has no member \"element_type\"\n",
      "                detected during:\n",
      "                  instantiation of \"T c10::generic_to(c10::IValue, c10::_fake_type<T>) [with T=std::optional<double>]\"\n",
      "      (1917): here\n",
      "                  instantiation of \"T c10::IValue::to<T>() && [with T=std::optional<double>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(499): here\n",
      "                  instantiation of \"std::decay_t<c10::guts::infer_function_traits<Functor>::type::return_type> c10::impl::call_functor_with_args_from_stack_<Functor,AllowDeprecatedTypes,ivalue_arg_indices...,ArgTypes...>(c10::OperatorKernel *, c10::DispatchKeySet, c10::Stack *, std::index_sequence<ivalue_arg_indices...>, c10::guts::typelist::typelist<ArgTypes...> *) [with Functor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false, ivalue_arg_indices=<0UL, 1UL, 2UL, 3UL, 4UL, 5UL, 6UL, 7UL, 8UL, 9UL, 10UL, 11UL, 12UL, 13UL, 14UL, 15UL, 16UL, 17UL, 18UL>, ArgTypes=<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(513): here\n",
      "                  instantiation of \"std::decay_t<c10::guts::infer_function_traits<Functor>::type::return_type> c10::impl::call_functor_with_args_from_stack<Functor,AllowDeprecatedTypes>(c10::OperatorKernel *, c10::DispatchKeySet, c10::Stack *) [with Functor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(584): here\n",
      "                  instantiation of \"void c10::impl::make_boxed_from_unboxed_functor<KernelFunctor, AllowDeprecatedTypes>::call(c10::OperatorKernel *, const c10::OperatorHandle &, c10::DispatchKeySet, c10::Stack *) [with KernelFunctor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/KernelFunction_impl.h(159): here\n",
      "                  instantiation of \"c10::KernelFunction c10::KernelFunction::makeFromUnboxedFunctor<AllowLegacyTypes,KernelFunctor>(std::unique_ptr<c10::OperatorKernel, std::default_delete<c10::OperatorKernel>>) [with AllowLegacyTypes=false, KernelFunctor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/KernelFunction_impl.h(181): here\n",
      "                  instantiation of \"c10::KernelFunction c10::KernelFunction::makeFromUnboxedFunction(FuncPtr) [with FuncPtr=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, AllowLegacyTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(131): here\n",
      "                  instantiation of \"torch::CppFunction::CppFunction(FuncPtr, std::enable_if_t<c10::is_compile_time_function_pointer<FuncPtr>::value, std::nullptr_t>) [with FuncPtr=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(659): here\n",
      "                  instantiation of \"torch::Library &torch::Library::impl(Name, Func &&, torch::_RegisterOrVerify) & [with Name=const char *, Func=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(742): here\n",
      "                  instantiation of \"torch::Library &torch::Library::impl(torch::detail::SelectiveStr<true>, Func &&) & [with Func=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(556): here\n",
      "      \n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/ivalue_inl.h(1785): error: class \"std::optional<int64_t>\" has no member \"element_type\"\n",
      "                detected during:\n",
      "                  instantiation of \"T c10::generic_to(c10::IValue, c10::_fake_type<T>) [with T=std::optional<int64_t>]\"\n",
      "      (1917): here\n",
      "                  instantiation of \"T c10::IValue::to<T>() && [with T=std::optional<int64_t>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(499): here\n",
      "                  instantiation of \"std::decay_t<c10::guts::infer_function_traits<Functor>::type::return_type> c10::impl::call_functor_with_args_from_stack_<Functor,AllowDeprecatedTypes,ivalue_arg_indices...,ArgTypes...>(c10::OperatorKernel *, c10::DispatchKeySet, c10::Stack *, std::index_sequence<ivalue_arg_indices...>, c10::guts::typelist::typelist<ArgTypes...> *) [with Functor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false, ivalue_arg_indices=<0UL, 1UL, 2UL, 3UL, 4UL, 5UL, 6UL, 7UL, 8UL, 9UL, 10UL, 11UL, 12UL, 13UL, 14UL, 15UL, 16UL, 17UL, 18UL>, ArgTypes=<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(513): here\n",
      "                  instantiation of \"std::decay_t<c10::guts::infer_function_traits<Functor>::type::return_type> c10::impl::call_functor_with_args_from_stack<Functor,AllowDeprecatedTypes>(c10::OperatorKernel *, c10::DispatchKeySet, c10::Stack *) [with Functor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/impl/make_boxed_from_unboxed_functor.h(584): here\n",
      "                  instantiation of \"void c10::impl::make_boxed_from_unboxed_functor<KernelFunctor, AllowDeprecatedTypes>::call(c10::OperatorKernel *, const c10::OperatorHandle &, c10::DispatchKeySet, c10::Stack *) [with KernelFunctor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>, AllowDeprecatedTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/KernelFunction_impl.h(159): here\n",
      "                  instantiation of \"c10::KernelFunction c10::KernelFunction::makeFromUnboxedFunctor<AllowLegacyTypes,KernelFunctor>(std::unique_ptr<c10::OperatorKernel, std::default_delete<c10::OperatorKernel>>) [with AllowLegacyTypes=false, KernelFunctor=c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor>, c10::guts::typelist::typelist<const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>>>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/boxing/KernelFunction_impl.h(181): here\n",
      "                  instantiation of \"c10::KernelFunction c10::KernelFunction::makeFromUnboxedFunction(FuncPtr) [with FuncPtr=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>, AllowLegacyTypes=false]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(131): here\n",
      "                  instantiation of \"torch::CppFunction::CppFunction(FuncPtr, std::enable_if_t<c10::is_compile_time_function_pointer<FuncPtr>::value, std::nullptr_t>) [with FuncPtr=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(659): here\n",
      "                  instantiation of \"torch::Library &torch::Library::impl(Name, Func &&, torch::_RegisterOrVerify) & [with Name=const char *, Func=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/torch/library.h(742): here\n",
      "                  instantiation of \"torch::Library &torch::Library::impl(torch::detail::SelectiveStr<true>, Func &&) & [with Func=c10::CompileTimeFunctionPointer<std::tuple<at::Tensor, at::Tensor, at::Tensor, at::Tensor> (const at::Tensor &, const at::Tensor &, const at::Tensor &, const at::Tensor &, const std::optional<at::Tensor> &, const at::Tensor &, const std::optional<at::Tensor> &, const std::optional<at::Tensor> &, int64_t, int64_t, const at::Tensor &, double, const at::Tensor &, const at::Tensor &, int64_t, __nv_bool, std::optional<double>, std::optional<int64_t>, std::optional<int64_t>), &<unnamed>::mem_efficient_attention_backward_cutlass>]\"\n",
      "      /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu(556): here\n",
      "      \n",
      "      24 errors detected in the compilation of \"/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_backward_generic.cu\".\n",
      "      [2/83] c++ -MMD -MF /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/attention.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/attention.cpp -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "      [3/83] c++ -MMD -MF /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/spmm.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cpu/spmm.cpp -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/spmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "      [4/83] c++ -MMD -MF /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/sddmm.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cpu/sddmm.cpp -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/sddmm.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "      [5/83] c++ -MMD -MF /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/sparse_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cpu/sparse_softmax.cpp -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/sparse_softmax.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "      [6/83] c++ -MMD -MF /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/matmul.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cpu/matmul.cpp -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cpu/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "      [7/83] c++ -MMD -MF /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/autograd/matmul.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/autograd/matmul.cpp -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/autograd/matmul.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "      [8/83] /usr/local/cuda-11.6/bin/nvcc  -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/sputnik -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/tools/util/include -I/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/third_party/cutlass/examples -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda-11.6/include -I/usr/include/python3.10 -c -c /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/xformers/csrc/attention/cuda/fmha/attention_cutlass_rand_uniform.cu -o /tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/build/temp.linux-x86_64-cpython-310/xformers/csrc/attention/cuda/fmha/attention_cutlass_rand_uniform.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -DHAS_PYTORCH --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --extended-lambda -D_ENABLE_EXTENDED_ALIGNED_STORAGE -std=c++17 --generate-line-info -DNDEBUG --use_fast_math -DXFORMERS_MEM_EFF_ATTENTION_DISABLE_BACKWARD --threads 4 --ptxas-options=-v --ptxas-options=-O2 --ptxas-options=-allow-expensive-optimizations=true -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_61,code=compute_61 -gencode=arch=compute_61,code=sm_61\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
      "                detected during:\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
      "      (61): here\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
      "      \n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
      "                detected during:\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
      "      (61): here\n",
      "                  instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
      "      /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
      "      \n",
      "      ptxas info    : 218049 bytes gmem, 72 bytes cmem[3]\n",
      "      ptxas info    : Compiling entry function '_ZN71_GLOBAL__N__90580979_33_attention_cutlass_rand_uniform_cu_4deaef15_185519rand_uniform_kernelIfEEvlllfN2at15PhiloxCudaStateEPT_l' for 'sm_61'\n",
      "      ptxas info    : Function properties for _ZN71_GLOBAL__N__90580979_33_attention_cutlass_rand_uniform_cu_4deaef15_185519rand_uniform_kernelIfEEvlllfN2at15PhiloxCudaStateEPT_l\n",
      "          0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "      ptxas info    : Used 40 registers, 392 bytes cmem[0]\n",
      "      ninja: build stopped: subcommand failed.\n",
      "      Traceback (most recent call last):\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 1893, in _run_ninja_build\n",
      "          subprocess.run(\n",
      "        File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
      "          raise CalledProcessError(retcode, process.args,\n",
      "      subprocess.CalledProcessError: Command '['ninja', '-v', '-j', '8']' returned non-zero exit status 1.\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/setup.py\", line 680, in <module>\n",
      "          setuptools.setup(\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\", line 104, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 184, in setup\n",
      "          return run_commands(dist)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 200, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 967, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/wheel/_bdist_wheel.py\", line 387, in run\n",
      "          self.run_command(\"build\")\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 967, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "          self.run_command(cmd_name)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py\", line 316, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 967, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\", line 91, in run\n",
      "          _build_ext.run(self)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "          _build_ext.build_ext.run(self)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 359, in run\n",
      "          self.build_extensions()\n",
      "        File \"/tmp/pip-wheel-ess9708s/xformers_bab7ac728c0f4bd29b95d92dd4d90434/setup.py\", line 637, in build_extensions\n",
      "          super().build_extensions()\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 843, in build_extensions\n",
      "          build_ext.build_extensions(self)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/Cython/Distutils/old_build_ext.py\", line 195, in build_extensions\n",
      "          _build_ext.build_ext.build_extensions(self)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 479, in build_extensions\n",
      "          self._build_extensions_serial()\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 505, in _build_extensions_serial\n",
      "          self.build_extension(ext)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/build_ext.py\", line 252, in build_extension\n",
      "          _build_ext.build_extension(self, ext)\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/command/build_ext.py\", line 560, in build_extension\n",
      "          objects = self.compiler.compile(\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 658, in unix_wrap_ninja_compile\n",
      "          _write_ninja_file_and_compile_objects(\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 1574, in _write_ninja_file_and_compile_objects\n",
      "          _run_ninja_build(\n",
      "        File \"/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py\", line 1909, in _run_ninja_build\n",
      "          raise RuntimeError(message) from e\n",
      "      RuntimeError: Error compiling objects for extension\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for xformers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py clean for xformers\n",
      "Failed to build xformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Failed to build one or more wheels\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt update && apt install jq\n",
    "pip install ninja\n",
    "\n",
    "TMP=$(mktemp -d)\n",
    "cd \"$TMP\"\n",
    "git clone --no-checkout https://github.com/facebookresearch/xformers.git\n",
    "cd xformers\n",
    "LATEST_TAG=$(git describe --tags `git rev-list --tags --max-count=1`)\n",
    "echo \"Building version: $LATEST_TAG\"\n",
    "\n",
    "XFORMERS_DISABLE_FLASH_ATTN=1 NVCC_FLAGS=\"--use_fast_math -DXFORMERS_MEM_EFF_ATTENTION_DISABLE_BACKWARD\" MAX_JOBS=$(nproc) pip wheel --no-dependencies --wheel-dir=\"$TMP\" \"git+https://github.com/facebookresearch/xformers.git@$LATEST_TAG#egg=xformers\"\n",
    "if [[ $? -eq 0 ]]; then\n",
    "    echo -e \"Finished!\\nMoving .whl to /notebooks/\"\n",
    "    cp \"$TMP\"/xformers-* /notebooks/\n",
    "    echo \"Here is your wheel file:\"\n",
    "    find /notebooks -name xformers-*.whl\n",
    "    echo \"Installing your new Xformers wheel...\"\n",
    "    pip install --force-reinstall --no-dependencies \"$TMP\"/xformers-*\n",
    "fi\n",
    "rm -rf \"$TMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-21T18:07:28.842146Z",
     "iopub.status.busy": "2024-12-21T18:07:28.841788Z",
     "iopub.status.idle": "2024-12-21T18:08:55.220424Z",
     "shell.execute_reply": "2024-12-21T18:08:55.218605Z",
     "shell.execute_reply.started": "2024-12-21T18:07:28.842115Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.0.1+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.15.2+cu118\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.1.2)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m146.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (1.26.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (9.5.0)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m148.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n",
      "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cu118) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision==0.15.2+cu118) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision==0.15.2+cu118) (2019.11.28)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89989 sha256=04e7816e6ccb29a3f932450ba57c5dd1ca211797dca80f61b2b7da3216c86700\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, triton, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2+cu121\n",
      "    Uninstalling torch-2.1.2+cu121:\n",
      "      Successfully uninstalled torch-2.1.2+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.2+cu121\n",
      "    Uninstalling torchvision-0.16.2+cu121:\n",
      "      Successfully uninstalled torchvision-0.16.2+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xformers 0.0.28.post3 requires torch==2.5.1, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cmake-3.25.0 lit-15.0.7 torch-2.0.1+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reset Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes AUTOMATIC1111 breaks something. Go to https://github.com/AUTOMATIC1111/stable-diffusion-webui/commits/master and choose a commit to revert to.\n",
    "\n",
    "If you're looking for a specific date, do: `git log --since='Sept 17 2022' --until='Sept 18 2022'`\n",
    "\n",
    "**This shouldn't delete your outputs or any changes you've made to files, but I'd back up anything important just to be safe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "from pathlib import Path\n",
    "%cd \"{Path(repo_storage_dir, 'stable-diffusion-webui')}\"\n",
    "!git reset --hard <commit>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Delete .ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter stores temporary files in folders named `.ipynb_checkpoints`. It gets a little excessive sometimes so if you're running low on storage space or getting weird errors about a directory named `.ipynb_checkpoints`, run this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "import subprocess\n",
    "!find /notebooks/ -type d -name .ipynb_checkpoints -type d -exec rm -rv {} +\n",
    "s = subprocess.run(f'find \"{repo_storage_dir}\" -type d -name .ipynb_checkpoints -exec rm -rv {{}} +', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reset storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will delete ALL your files in `/notebooks/`, `/storage/`, `model_storage_dir`, and `repo_storage_dir`. Use if you're having issues with zero storage space and you don't want to delete your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the lines below to run this block. You can highlight the lines and do ctrl + /\n",
    "# %store -r model_storage_dir repo_storage_dir\n",
    "# try:\n",
    "#     test = [model_storage_dir, repo_storage_dir]\n",
    "# except NameError as e:\n",
    "#     print(\"There is an issue with your variables.\")\n",
    "#     print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "#     print('Error:', e)\n",
    "#     import sys\n",
    "#     sys.exit(1)\n",
    "# !rm -rf /storage/*\n",
    "# !mv /notebooks/*.ipynb / # move the notebook out of the directory before we nuke it\n",
    "# !rm -rf /notebooks/*\n",
    "# !mv /*.ipynb /notebooks/ # move it back\n",
    "# !rm -rf {model_storage_dir}\n",
    "# !rm -rf {repo_storage_dir}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
